<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ThreadLocal源码解析]]></title>
    <url>%2F2019%2F08%2F13%2FThreadLocal%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ThreadLocal的作用ThreadLocal的作用是提供线程内的局部变量，说白了，就是在各线程内部创建一个变量的副本，相比于使用各种锁机制访问变量，ThreadLocal的思想就是用空间换时间，使各线程都能访问属于自己这一份的变量副本，变量值不互相干扰，减少同一个线程内的多个函数或者组件之间一些公共变量传递的复杂度。 ThreadLocal特性及使用场景 1、方便同一个线程使用某一对象，避免不必要的参数传递； 2、线程间数据隔离（每个线程在自己线程里使用自己的局部变量，各线程间的ThreadLocal对象互不影响）； 3、获取数据库连接、Session、关联ID（比如日志的uniqueID，方便串起多个日志）； ThreadLocal应注意 1、ThreadLocal并未解决多线程访问共享对象的问题； 2、ThreadLocal并不是每个线程拷贝一个对象，而是直接new（新建）一个； 3、如果ThreadLocal.set()的对象是多线程共享的，那么还是涉及并发问题。 图解TreadLocal 每个线程可能有多个ThreadLocal，同一线程的各个ThreadLocal存放于同一个ThreadLocalMap中。 图解ThreadLocal(JDK8).vsdx原图下载地址：https://github.com/zxiaofan/JDK-Study/tree/master/src/java1/lang/threadLocal 内部类ThreadLocalMap1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; /** * ThreadLocalMap的key是ThreadLocal * value是Object（即我们所谓的“线程本地数据”） */ Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; /** * 初始容量，2的幂等次方 */ private static final int INITIAL_CAPACITY = 16; /** * 实际保存数据的数组，超过threshold会2倍扩容 */ private Entry[] table; /** * 实际存储的entry数量 */ private int size = 0; /** * 下次扩容的阈值 */ private int threshold; // Default to 0 /** * Set the resize threshold to maintain at worst a 2/3 load factor. */ private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; /** * 往后移动一位 */ private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0); &#125; /** * 往前移动一位 */ private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1); &#125; /** * Construct a new map initially containing (firstKey, firstValue). * ThreadLocalMaps懒汉模式, 等第一个entry被放入时才初始化. */ ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125; /** * 将父线程的ThreadLocalMaps内容复制过来 * Called only by createInheritedMap. */ private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (int j = 0; j &lt; len; j++) &#123; Entry e = parentTable[j]; if (e != null) &#123; @SuppressWarnings("unchecked") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125; &#125;&#125; ThreadLocalMap是定制的hashMap，仅用于维护当前线程的本地变量值。仅ThreadLocal类对其有操作权限，是Thread的私有属性。为避免占用空间较大或生命周期较长的数据常驻于内存引发一系列问题，hash table的key是弱引用WeakReferences。当空间不足时，会清理未被引用的entry。这时Entry里的key为null了，那么直到线程结束前，Entry中的value都是无法回收的，这里可能产生内存泄露。 SuppliedThreadLocal12345678910111213static final class SuppliedThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; private final Supplier&lt;? extends T&gt; supplier; SuppliedThreadLocal(Supplier&lt;? extends T&gt; supplier) &#123; this.supplier = Objects.requireNonNull(supplier); &#125; @Override protected T initialValue() &#123; return supplier.get(); &#125;&#125; SuppliedThreadLocal是JDK8新增的内部类，只是扩展了ThreadLocal的初始化值的方法而已，允许使用JDK8新增的Lambda表达式赋值。需要注意的是，函数式接口Supplier不允许为null。 初始化123456789101112131415161718192021222324252627282930313233public class ThreadLocal&lt;T&gt; &#123; /** * ThreadLocal初始化时会调用nextHashCode()方法初始化 * threadLocalHashCode，且threadLocalHashCode初始化后不可变。 * threadLocalHashCode可用来标记不同的ThreadLocal实例。 */ private final int threadLocalHashCode = nextHashCode(); private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125; protected T initialValue() &#123; return null; &#125; /** * JDK8新增，支持Lambda表达式，和ThreadLocal重写的initialValue()效果一样。 */ public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier) &#123; return new SuppliedThreadLocal&lt;&gt;(supplier); &#125; public ThreadLocal() &#123; &#125;&#125; ThreadLocal类变量有3个，其中2个是静态变量（包括一个常量），实际作为作为ThreadLocal实例的变量只有threadLocalHashCode这1个，而且已经初始化就不可变了。 其中withInitial()方法使用示例： 123456789101112131415161718192021public void jdk8Test()&#123; Supplier&lt;String&gt; supplier =new Supplier&lt;String&gt;()&#123; @Override public String get()&#123; return"supplier_new"; &#125; &#125;; threadLocal= ThreadLocal.withInitial(supplier); System.out.println(threadLocal.get()); // supplier_new // Lambda表达式 threadLocal= ThreadLocal.withInitial(()-&gt;"sup_new_2"); System.out.println(threadLocal.get()); // sup_new_2 ThreadLocal&lt;DateFormat&gt; localDate = ThreadLocal.withInitial(()-&gt;new SimpleDateFormat("yyyy-MM-dd")); System.out.println(localDate.get().format(new Date())); // 2017-01-22 ThreadLocal&lt;String&gt; local =new ThreadLocal&lt;&gt;().withInitial(supplier); System.out.println(local.get()); // supplier_new&#125; 源码分析get方法12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 直接看代码，可以分析主要有以下几步： 获取当前的Thread对象，通过getMap获取Thread内的ThreadLocalMap 如果map已经存在，以当前的ThreadLocal为键，获取Entry对象，并从从Entry中取出值 否则，调用setInitialValue进行初始化。 getMap123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; getMap很简单，就是返回线程中ThreadLocalMap，跳到Thread源码里看，ThreadLocalMap是这么定义的： 1ThreadLocal.ThreadLocalMap threadLocals = null; 所以ThreadLocalMap还是定义在ThreadLocal里面的，我们前面已经说过ThreadLocalMap中的Entry定义，下面为了先介绍ThreadLocalMap的定义我们把setInitialValue放在前面说。 setInitialValue12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; setInititialValue在Map不存在的时候调用。 首先是调用initialValue生成一个初始的value值，深入initialValue函数，我们可知它就是返回一个null，如果创建ThreadLocal时调用withInitial() 方法指定了初始方法，则返回自定义值； 还是在get()一下Map，如果map存在，则直接map.set(), 这个函数会放在后文说； 如果map不存在，则会调用createMap()创建ThreadLocalMap。 createMap123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 比较简单，就是调用了ThreadLocalMap内部类的构造函数而已。 map.getEntry12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; 首先是计算索引位置i，通过计算key的hash%(table.length-1)得出； 根据获取Entry，如果Entry存在且Entry的key恰巧等于ThreadLocal，那么直接返回Entry对象； 否则，也就是在此位置上找不到对应的Entry，那么就调用getEntryAfterMiss。 getEntryAfterMiss12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; 这个方法我们还得结合上一步看，上一步是因为不满足 1e != null &amp;&amp; e.get() == key 才沦落到调用getEntryAfterMiss的，所以: 首先e如果为null的话，证明不存在value, 那么getEntryAfterMiss还是直接返回null的 如果是不满足e.get() == key，那么进入while循环，这里是不断循环，如果e一直不为空，那么就调用nextIndex，不断递增i，在此过程中一直会做两个判断： 如果 k == key, 那么代表找到了这个所需要的Entry，直接返回； 如果 k == null，那么证明这个Entry中key已经为null, 那么这个Entry就是一个过期对象，这里调用expungeStaleEntry清理该Entry。这里解答了前面留下的一个坑，即ThreadLocal Ref销毁时，ThreadLocal实例由于只有Entry中的一条弱引用指着，那么就会被GC掉，Entry的key没了，value可能会内存泄露的，其实在每一个get，set操作时都会不断清理掉这种key为null的Entry的。 为什么循环查找？ 这里你可以直接跳到下面的set方法，主要是因为处理哈希冲突的方法，我们都知道HashMap采用拉链法处理哈希冲突，即在一个位置已经有元素了，就采用链表把冲突的元素链接在该元素后面，而ThreadLocal采用的是开放地址法，即有冲突后，把要插入的元素放在要插入的位置后面为null的地方 具体关于这两种方法的区别可以参考：解决哈希（HASH）冲突的主要方法。 所以上面的循环就是因为我们在第一次计算出来的i位置不一定存在key与我们想查找的key恰好相等的Entry，所以只能不断在后面循环，来查找是不是被插到后面了，直到找到为null的元素，因为若是插入也是到null为止的。 expungeStaleEntry12345678910111213141516171819202122232425262728293031323334private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // （1）删掉staleSlot位置value值 tab[staleSlot].value = null; tab[staleSlot] = null; size--; // （2）Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; // 删除元素后，需要重新移动存活的元素，因为查找时遇到null会终止 int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; 看上面这段代码主要有两部分： (1) 这段主要是将i位置上的Entry的value设为null，Entry的引用也设为null，那么系统GC的时候自然会清理掉这块内存； (2) 这段就是扫描位置staleSlot之后，null之前的Entry数组，清除每一个key为null的Entry，同时若是key不为空，做rehash，调整其位置。 为什么要做rehash呢？ 因为我们在清理的过程中会把某个值设为null，那么这个值后面的区域如果之前是连着前面的，那么下次循环查找时，就会只查到null为止。 举个例子就是： …, &lt;key1(hash1), value1&gt;, &lt;key2(hash1), value2&gt;,… 即key1和key2的hash值相同, 此时，若插入 &lt;key3(hash2), value3&gt; 其hash计算的目标位置被 &lt;key2(hash1), value2&gt; 占了，于是往后寻找可用位置，hash表可能变为： …, &lt;key1(hash1), value1&gt;, &lt;key2(hash1), value2&gt;, &lt;key3(hash2), value3&gt;, … 此时，若 &lt;key2(hash1), value2&gt; 被清理，显然 &lt;key3(hash2), value3&gt;应该往前移(即通过rehash调整位置)，否则若以key3查找hash表，将会找不到key3。 set方法我们在get方法的循环查找那里也大概描述了set方法的思想，即开放地址法,下面看具体代码： 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 首先也是获取当前线程，根据线程获取到ThreadLocalMap，若是有ThreadLocalMap，则调用 1map.set(ThreadLocal&lt;?&gt; key, Object value) 若是没有则调用createMap创建。 map.set1234567891011121314151617181920212223242526private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 看上面这段代码： 首先还是根据key计算出位置i，然后查找i位置上的Entry， 若是Entry已经存在并且key等于传入的key，那么这时候直接给这个Entry赋新的value值。 若是Entry (e != null) 存在，但是key为null，则调用replaceStaleEntry来更换这个key为空的Entry 不断循环检测，直到遇到为null的地方，这时候要是还没在循环过程中return，那么就在这个null的位置新建一个Entry，并且插入，同时size增加1。 最后调用cleanSomeSlots，这个函数就不细说了，你只要知道内部还是调用了上面提到的expungeStaleEntry函数清理key为null的Entry就行了，最后返回是否清理了Entry，接下来再判断 sz&gt;thresgold ,这里就是判断是否达到了rehash的条件，达到的话就会调用rehash函数。 上面这段代码有两个函数还需要分析下，首先是: replaceStaleEntry123456789101112131415161718192021222324252627282930313233343536373839404142434445private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // 向前找到key为null的位置 int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // staleSlot节点key为空，属于应该清理节点 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; // 更新value值 tab[i] = tab[staleSlot]; // i指向key为空节点 tab[staleSlot] = e; // staleSlot前面全不为空，i节点指向最新key为null位置 if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // 更新key为空节点位置 if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // If key not found, put new entry in stale slot tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // If there are any other stale entries in run, expunge them if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125; 首先我们回想上一步是因为这个位置的Entry的key为null才调用replaceStaleEntry。 第1个for循环：我们向前找到key为null的位置，记录为slotToExpunge,这里是为了后面的清理过程，可以不关注了； 第2个for循环：我们从staleSlot起到下一个null为止，若是找到key和传入key相等的Entry，就给这个Entry赋新的value值，并且把它和staleSlot位置的Entry交换，然后调用CleanSomeSlots清理key为null的Entry。 若是一直没有key和传入key相等的Entry，那么就在staleSlot处新建一个Entry。函数最后再清理一遍空key的Entry。 说完replaceStaleEntry，还有个重要的函数是rehash以及rehash的条件： 首先是sz &gt; threshold时调用rehash rehash12345678private void rehash() &#123; // 清理全部空节点 expungeStaleEntries(); // Use lower threshold for doubling to avoid hysteresis if (size &gt;= threshold - threshold / 4) resize();&#125; 清理完空key的Entry后，如果size大于3/4的threshold，则调用resize函数： resize123456789101112131415161718192021222324252627private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC 下次gc会被回收 &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; 由源码我们可知每次扩容大小扩展为原来的2倍，然后再一个for循环里，清除空key的Entry，同时重新计算key不为空的Entry的hash值，把它们放到正确的位置上，再更新ThreadLocalMap的所有属性。 remove最后一个需要探究的就是remove函数，它用于在map中移除一个不用的Entry。也是先计算出hash值，若是第一次没有命中，就循环直到null，在此过程中也会调用expungeStaleEntry清除空key节点。代码如下： 1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; 使用ThreadLocal的最佳实践我们发现无论是set,get还是remove方法，过程中key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，GC时就会被回收。那么怎么会存在内存泄露呢？但是以上的思路是假设你调用get或者set方法了，很多时候我们都没有调用过，所以最佳实践就是: 使用者需要手动调用remove函数，删除不再使用的ThreadLocal. 尽量将ThreadLocal设置成private static的，这样ThreadLocal会尽量和线程本身一起消亡。 问题与思考（1）如果有多个ThreadLocal都对同一个线程ThreadLocalMap写数据时，可能存在hash位置冲突，导致set()和get()效率显著下降； （2）ThreadLocal不能读取父线程的ThradLocalMap内容，需要使用InheritableThreadLocal；]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法-入门]]></title>
    <url>%2F2019%2F08%2F12%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[数组数组，将元素存储到内存的连续位置中，是最基本的数据结构。在任何和编程相关的面试中，都会被问到和数组相关的问题，可以说是非常热门的考题之一。比如：将数组反转、对数组进行排序、搜索数组中的元素等。 数组数据结构的主要优点是如果知道索引就可以通过 O(l) 进行快速搜索，但是在数组中添加和删除元素的速度会很慢，因为数组一旦被创建，就无法更改其大小。如果需要创建更长或更短的数组，得先创建一个新数组，再把原数组中的所有元素复制到新创建的数组中。 解决数组相关问题的关键是要熟悉数组的数据结构和基本的构造，如循环、递归等等；下面给出了 10 道热门面试题帮助大家掌握知识并进行练习。 1. 给定一个 1-100 的整数数组，请找到其中缺少的数字。解决方法与代码：https://javarevisited.blogspot.com/2014/11/how-to-find-missing-number-on-integer-array-java.html 两种思路：（1）如果只缺少一个数字，n*(n+1)/2 - sum 就是缺失的数字；（2）缺失多个数字或是某些数字重复出现，则只能遍历一遍，记录哪些数字出现过，可用List或BitSet来记录。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 给定一个 1-n 的整数数组，请找到其中缺少的数字 * * @author austin * @since 2019/7/30 14:31 */public class FindMissingNumber &#123; /** * 支持多个重复或是缺失多个情况 * * @param arr 数组 * @param count n */ public static void printMissingNumber(int[] arr, int count) &#123; int missingCount = count - arr.length; BitSet bitSet = new BitSet(count); for (int i : arr) &#123; bitSet.set(i - 1); &#125; int lastIndex = 0; for (int i = 0; i &lt; missingCount; i++) &#123; lastIndex = bitSet.nextClearBit(lastIndex); System.out.println(++lastIndex); &#125; &#125; /** * 只支持缺失1个情况 */ public static void printSingleMissingNumber(int[] arr, int count) &#123; int exceptedSum = count * (count + 1) / 2; int sum = 0; for (int i : arr) &#123; sum += i; &#125; System.out.println(exceptedSum - sum); &#125; public static void main(String[] args) &#123; // 缺失一个数字 printMissingNumber(new int[] &#123;1, 2, 3, 4, 6&#125;, 6); // 缺失3个数字 printMissingNumber(new int[] &#123;1, 2, 3, 4, 6, 9, 8&#125;, 10); // 缺失一个数字 printSingleMissingNumber(new int[] &#123;1, 2, 3, 4, 6&#125;, 6); &#125;&#125; 2. 在给定的成对整数数组中，请找出所有总和等于给定数字的组合。解决方法与代码：http://javarevisited.blogspot.com/2014/08/how-to-find-all-pairs-in-array-of-integers-whose-sum-equal-given-number-java.html 三种思路：（1）两层循环，时间复杂度O(n^2);（2）存储到HashTable里，在HashTable里找（sum - arr[i]）值， 时间复杂度： O(n), 空间复杂度： O(n);（3）先排序O(nlogn), 然后首尾想加，往中间靠； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import java.util.Arrays;import java.util.HashSet;import java.util.Set;/** * 在给定的成对整数数组中，请找出所有总和等于给定数字的组合 * * @author austin * @since 2019/7/30 15:35 */public class ComposeSum &#123; /** * 可输出全部组合 * 两层循环 */ public static void printPairs(int[] array, int sum) &#123; for (int i = 0; i &lt; array.length; i++) &#123; int first = array[i]; for (int j = i + 1; j &lt; array.length; j++) &#123; int second = array[j]; if ((first + second) == sum) &#123; System.out.printf("(%d, %d) %n", first, second); &#125; &#125; &#125; &#125; /** * map方式 */ public static void printPairsUsingSet(int[] numbers, int n) &#123; if (numbers.length &lt; 2) &#123; return; &#125; Set set = new HashSet(numbers.length); for (int value : numbers) &#123; int target = n - value; // if target number is not in set then add if (!set.contains(target)) &#123; set.add(value); &#125; else &#123; System.out.printf("(%d, %d) %n", value, target); &#125; &#125; &#125; /** * 先排序 O(n log(n)) */ public static void printPairsUsingTwoPointers(int[] numbers, int k) &#123; if (numbers.length &lt; 2) &#123; return; &#125; Arrays.sort(numbers); int left = 0; int right = numbers.length - 1; while (left &lt; right) &#123; int sum = numbers[left] + numbers[right]; if (sum == k) &#123; System.out.printf("(%d, %d) %n", numbers[left], numbers[right]); left = left + 1; right = right - 1; &#125; else if (sum &lt; k) &#123; left = left + 1; &#125; else if (sum &gt; k) &#123; right = right - 1; &#125; &#125; &#125; public static void main(String[] args)&#123; printPairs(new int[]&#123; 2, 4, 3, 5, 6, -2, 4, 7, 8, 9 &#125;, 12); System.out.println(); printPairsUsingSet(new int[]&#123; 2, 4, 3, 5, 6, -2, 4, 7, 8, 9 &#125;, 12); System.out.println(); printPairsUsingTwoPointers(new int[]&#123; 2, 4, 3, 5, 6, -2, 4, 7, 8, 9 &#125;, 12); &#125;&#125; 3. 数组中重复的数据给定一个整数数组 a，其中1 ≤ a[i] ≤ n （n为数组长度）, 其中有些元素出现两次而其他元素出现一次。 找到所有出现两次的元素。 你可以不用到任何额外空间并在O(n)时间复杂度内解决这个问题吗？ 示例： 输入: 1[4,3,2,7,8,2,3,1] 输出: 1[2,3] 解题思路：这个题目开头暗示了n的范围，所以可以加以利用，将元素转换成数组的索引并对应的将该处的元素乘以-1； 若数组索引对应元素的位置本身就是负数，则表示已经对应过一次；在结果列表里增加该索引的正数就行； 1234567891011121314151617class Solution &#123; public List&lt;Integer&gt; findDuplicates(int[] nums) &#123; List&lt;Integer&gt; dupliacates = new ArrayList&lt;Integer&gt;(); for(int i : nums)&#123; if(i &lt; 0)&#123; i = -i; &#125; if(nums[i-1] &lt; 0)&#123; // 已经重复过 dupliacates.add(i); continue; &#125; nums[i-1] = -1 * nums[i-1]; &#125; return dupliacates; &#125;&#125; 4. 快速排序快排采用的是分治的思想。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import java.util.Arrays;/** * 快速排序 * * @author austin * @since 2019/7/30 20:05 */public class QuickSort &#123; public static void sort(int[] nums) &#123; if (null == nums || nums.length == 0) &#123; return; &#125; quickSort(nums, 0, nums.length - 1); &#125; private static void quickSort(int[] nums, int low, int high) &#123; // 选取中位数 int pivot = nums[low + (high - low) / 2]; int left = low; int right = high; while (left &lt;= right) &#123; while (nums[left] &lt; pivot) &#123; left++; &#125; while (nums[right] &gt; pivot) &#123; right--; &#125; if (left &lt;= right) &#123; int temp = nums[left]; nums[left] = nums[right]; nums[right] = temp; left++; right--; &#125; &#125; if (low &lt; right) &#123; quickSort(nums, low, right); &#125; if (high &gt; left) &#123; quickSort(nums, left, high); &#125; &#125; public static void main(String[] args)&#123; int[] unsorted = &#123;6, 5, 3, 1, 8, 7, 2, 4&#125;; System.out.println("Unsorted array :" + Arrays.toString(unsorted)); sort(unsorted); System.out.println("Sorted array :" + Arrays.toString(unsorted)); &#125;&#125; 链表链表是另一种常见的数据结构，和数组相似，链表也是线性的数据结构并且以线性方式存储元素。而与数组不同的是，链表不是将元素存储在连续的位置中，而是可以存储在任意位置，彼此之间通过节点相互连接。 链表也可以说就是一个节点列表，每个节点中包含存储的值和下一个节点的地址。也正是因为这种结构，在链表里添加和删除元素很容易，你只需要更改链接而不用创建新的数组。但是搜索会很困难，并且在单链表中找到一个元素就需要 O（n）个时间。 链表有多种形式，如：单链表，允许你在一个方向上进行遍历；双链表，可以在两个方向上进行遍历；循环链表，最后节点的指针指向第一个节点从而形成一个环形的链；因为链表是一种递归数据结构，所以在解决链表问题时，熟练掌握递归算法就显得更加重要了。 1. 判断单链表是否存在环及求环入口点 先判断是否有环设置两个指针(fast, slow)，初始值都指向头，slow每次前进一步，fast每次前进二步，如果链表存在环，则fast必定先进入环，而slow后进入环，两个指针必定相遇。(当然，fast先行头到尾部为NULL，则为无环链表) 1234567891011121314151617181920212223242526272829/** * Definition for singly-linked list. * class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; * val = x; * next = null; * &#125; * &#125; */public class Solution &#123; public boolean hasCycle(ListNode head) &#123; ListNode slow = head; ListNode quick = head; while(null != quick)&#123; if(quick.next != null &amp;&amp; null != quick.next.next)&#123; quick = quick.next.next; &#125;else&#123; return false; &#125; slow = slow.next; if(slow == quick)&#123; return true; &#125; &#125; return false; &#125;&#125; 此问题可扩展至： 求循环链表任一节点“对面的”（最远端）的节点 算法同上，当quick到达起始节点或起始节点next时，slow指示的就是最远端的节点。 经过第1步确认存在环后，寻找环入口点： 算法描述： 当quick若与slow相遇时，slow肯定没有走遍历完链表，而quick已经在环内循环了n圈(1&lt;=n)。假设slow走了s步，则fast走了2s步（fast步数还等于s 加上在环上多转的n圈），设环长为r，则： 122s = s + nrs = nr 设整个链表长L，入口环与相遇点距离为x，起点到环入口点的距离为a。 12345a + x = s = nra + x = (n–1)r + r = (n-1)r + L - aa = (n-1)r + (L – a – x) (L – a – x) 为相遇点到环入口点的距离，由此可知，从链表头到环入口点等于(n-1)循环内环+相遇点到环入口点 于是我们从链表头、与相遇点分别设一个指针，每次各走一步，两个指针必定相遇，且相遇第一点为环入口点。 123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; * val = x; * next = null; * &#125; * &#125; */public class Solution &#123; public ListNode hasCycle(ListNode head) &#123; ListNode slow = head; ListNode quick = head.next.next; // 一定有环， 寻找相遇点 while(slow != quick)&#123; slow = slow.next; quick = quick.next.next; &#125; // quick指针重新指向head节点 quick = head; while(slow != quick)&#123; slow = slow.next; quick = quick.next; &#125; return slow; &#125;&#125; 此问题可扩展至： 判断两个单链表是否相交，如果相交，给出相交的第一个点（两个链表都不存在环）。 根据问题描述，两个单链表自相交点起，将合并为一个单链表，这是理解算法的关键。 算法描述： 将其中一个链表首尾相连，检测另外一个链表是否存在环，如果存在，则两个链表相交，而检测出来的依赖环入口即为相交的第一个点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; * val = x; * next = null; * &#125; * &#125; */public class Solution &#123; public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; if(null == headA || null == headB)&#123; return null; &#125; // 先将一个链表构成环 ListNode tail = headA; while(tail.next != null)&#123; tail = tail.next; &#125; tail.next = headA; ListNode slow = headB; ListNode quick = headB; while(quick != null)&#123; if(null != quick.next &amp;&amp; null != quick.next.next)&#123; quick = quick.next.next; &#125;else&#123; tail.next = null; return null; &#125; slow = slow.next; if(slow == quick)&#123; break; &#125; &#125; // 能够执行到此处一定是有环 quick = headB; while(slow != quick)&#123; slow = slow.next; quick = quick.next; &#125; tail.next = null; return slow; &#125;&#125; 2. 单链表相交找到两个单链表相交的起始节点。 注意：如果两个链表没有交点，返回 null.在返回结果后，两个链表仍须保持原有的结构。可假定整个链表结构中没有循环。程序尽量满足 O(n) 时间复杂度，且仅用 O(1) 内存。 解题思路：双指针法 创建两个指针 pA 和 pB，分别初始化为链表 A 和 B 的头结点。然后让它们向后逐结点遍历。 当 pA 到达链表的尾部时，将它重定位到链表 B 的头结点 (你没看错，就是链表 B); 类似的，当 pB 到达链表的尾部时，将它重定位到链表 A 的头结点。 若在某一时刻 pA 和 pB 相遇，则 pA/pB 为相交结点。 想弄清楚为什么这样可行, 可以考虑以下两个链表: A={1,3,5,7,9,11} 和 B={2,4,9,11}，相交于结点 9。由于 B.length (=4) &lt; A.length (=6)，pB 比 pA 少经过 2 个结点，会先到达尾部。将 pB 重定向到 A 的头结点，pA 重定向到 B 的头结点后，pB 要比 pA 多走 2 个结点。因此，它们会同时到达交点。如果两个链表存在相交，它们末尾的结点必然相同。因此当 pA/pB 到达链表结尾时，记录下链表 A/B 对应的元素。若最后元素不相同，则两个链表不相交。 复杂度分析 时间复杂度 : O(m+n)O(m+n)。空间复杂度 : O(1)O(1)。 123456789101112131415161718192021222324252627/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; * val = x; * next = null; * &#125; * &#125; */public class Solution &#123; public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; if(headA == null || headB == null) &#123; return null; &#125; ListNode pA = headA, pB = headB; // 在这里第一轮体现在pA和pB第一次到达尾部会移向另一链表的表头, // 而第二轮体现在如果pA或pB相交就返回交点, 不相交最后就是null==null while(pA != pB)&#123; pA = pA == null ? headB : pA.next; pB = pB == null ? headA : pB.next; &#125; return pA; &#125;&#125; 3. 反转单链表两种思路：（1）迭代假设存在链表 1 → 2 → 3 → Ø，我们想要把它改成 Ø ← 1 ← 2 ← 3。 在遍历列表时，将当前节点的 next 指针改为指向前一个元素。由于节点没有引用其上一个节点，因此必须事先存储其前一个元素。在更改引用之前，还需要另一个指针来存储下一个节点。不要忘记在最后返回新的头引用！ 12345678910111213141516171819202122/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode reverseList(ListNode head) &#123; ListNode prev = null; ListNode cur = head; ListNode next = null; while(cur != null)&#123; next = cur.next; cur.next = prev; prev = cur; cur = next; &#125; return prev; &#125;&#125; 复杂度分析 时间复杂度：O(n)，假设 n 是列表的长度，时间复杂度是 O(n)。空间复杂度：O(1)。 （2）递归核心思想： 1head.next.next = head 12345678910111213141516171819/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode reverseList(ListNode head) &#123; if(head == null || head.next == null)&#123; return head; &#125; ListNode p = reverseList(head.next); head.next.next = head; head.next = null; return p; &#125;&#125; 复杂度分析 时间复杂度：O(n)，假设 n 是列表的长度，那么时间复杂度为 O(n)。空间复杂度：O(n)，由于使用递归，将会使用隐式栈空间。递归深度可能会达到 n 层。 4. 删除链表的倒数第N个节点双指针法：第一个指针从列表的开头向前移动 n+1n+1 步，而第二个指针将从列表的开头出发。现在，这两个指针被 n 个结点分开。我们通过同时移动两个指针向前来保持这个恒定的间隔，直到第一个指针到达最后一个结点。此时第二个指针将指向从最后一个结点数起的第 n 个结点。我们重新链接第二个指针所引用的结点的 next 指针指向该结点的下下个结点。 123456789101112131415161718192021222324252627/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode removeNthFromEnd(ListNode head, int n) &#123; ListNode dummy = new ListNode(0); // 哑指针，防止极端情况 dummy.next = head; ListNode first = dummy; ListNode second = dummy; // Advances first pointer so that the gap between first and second is n nodes apart for (int i = 1; i &lt;= n + 1; i++) &#123; first = first.next; &#125; // Move first to the end, maintaining the gap while (first != null) &#123; first = first.next; second = second.next; &#125; second.next = second.next.next; return dummy.next; &#125;&#125; 二叉树二叉树是一种非常重要的数据结构，很多其它数据结构都是基于二叉树的基础演变而来的。 对于二叉树，有深度遍历和广度遍历，深度遍历有前序、中序以及后序三种遍历方法，广度遍历即我们平常所说的层次遍历。 因为树的定义本身就是递归定义，因此采用递归的方法去实现树的三种遍历不仅容易理解而且代码很简洁，而对于广度遍历来说，需要其他数据结构的支撑，比如堆了。所以，对于一段代码来说，可读性有时候要比代码本身的效率要重要的多。 1. 二叉树深度遍历 递归方式 1234567891011121314151617181920212223242526272829303132/*** 前序遍历*/ public void preOrderTraverse1(TreeNode root) &#123; if (root != null) &#123; System.out.print(root.val+" "); preOrderTraverse1(root.left); preOrderTraverse1(root.right); &#125;&#125;/*** 中序遍历*/ public void inOrderTraverse1(TreeNode root) &#123; if (root != null) &#123; inOrderTraverse1(root.left); System.out.print(root.val+" "); inOrderTraverse1(root.right); &#125;&#125;/*** 后序遍历*/ public void postOrderTraverse1(TreeNode root) &#123; if (root != null) &#123; postOrderTraverse1(root.left); postOrderTraverse1(root.right); System.out.print(root.val+" "); &#125;&#125; 非递归方式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/*** 前序遍历*/public void preOrderTraverse(TreeNode root) &#123; LinkedList&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) &#123; if (cur != null) &#123; System.out.println(cur.val); stack.push(cur); cur = cur.left; &#125; else &#123; cur = stack.pop(); cur = cur.right; &#125; &#125;&#125;/*** 中序遍历*/public void midOrderTraverse(TreeNode root) &#123; LinkedList&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) &#123; if (cur != null) &#123; stack.push(cur); cur = cur.left; &#125; else &#123; cur = stack.pop(); System.out.println(cur.val); cur = cur.right; &#125; &#125;&#125;/*** 后序遍历*/public void postOrderTraverse(TreeNode root) &#123; LinkedList&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) &#123; if (cur != null) &#123; stack.push(cur); cur = cur.right; &#125; else &#123; cur = stack.pop(); System.out.println(cur.val); cur = cur.left; &#125; &#125;&#125; 2. 二叉树层遍历层次遍历的代码比较简单，只需要一个队列即可，先在队列中加入根结点。之后对于任意一个结点来说，在其出队列的时候，访问之。同时如果左孩子和右孩子有不为空的，入队列。代码如下： 1234567891011121314151617181920public void levelTraverse(TreeNode root)&#123; if(root == null)&#123; return; &#125; LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); TreeNode cur; while (!queue.isEmpty())&#123; cur = queue.poll(); System.out.print(cur.val); if (cur.left != null)&#123; queue.offer(cur.left); &#125; if (cur.right != null)&#123; queue.offer(cur.right); &#125; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机性能监控与故障处理工具]]></title>
    <url>%2F2019%2F08%2F12%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[概述本文参考的是周志明的 《深入理解Java虚拟机》 第四章 ，为了整理思路，简单记录一下，方便后期查阅。 JDK本身提供了很多方便的JVM性能调优监控工具，除了集成式的VisualVM和jConsole外，还有jps、jstack、jmap、jhat、jstat、hprof等小巧的工具，本文希望能起抛砖引玉之用，让大家能开始对JVM性能调优的常用工具有所了解。 JDK的命令行工具 命令名称 全称 用途 jstat JVM Statistics Monitoring Tool 用于收集Hotspot虚拟机各方面的运行数据 jps JVM Process Status Tool 显示指定系统内所有的HotSpot虚拟机进程 jinfo Configuration Info for Java 显示虚拟机配置信息 jmap JVM Memory Map 生成虚拟机的内存转储快照，生成heapdump文件 jhat JVM Heap Dump Browser 用于分析heapdump文件，它会建立一个HTTP/HTML服务器，让用户在浏览器上查看分析结果 jstack JVM Stack Trace 显示虚拟机的线程快照 详情参考： https://www.ymq.io/2017/08/01/jvm-4/]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java多线程面试集锦]]></title>
    <url>%2F2019%2F08%2F01%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%9D%A2%E8%AF%95%E9%9B%86%E9%94%A6%2F</url>
    <content type="text"><![CDATA[什么是线程？进程？协程？进程 具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.（比如一个qq程序就是一个进程或者多个进程），系统进行资源分配的最小单位.。进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全 线程程序执行流的最小单元（操作系统可识别的最小执行和调度单位）。也可以理解线程是一个程序里面不同的执行路径。是为了提高cpu的利用率而设计的。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。线程是轻量级的进程，它们是共享在父进程拥有的资源下，每个线程在父进程的环境中顺序的独立的执行一个活动，每个CPU核心在同一时刻只能执行一个线程，尽管我们有时感觉自己的计算机同时开着多个任务，其实他们每个的执行都是走走停停的，CPU轮流给每个进程及线程分配时间。 协程（线程的线程）协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。 什么是线程安全和线程不安全？ 通俗的说：加锁的就是是线程安全的，不加锁的就是是线程不安全的 线程安全就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问，直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。 一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分成两组，线程安全和非线程安全的。 Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。 线程不安全线程不安全：就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。线程安全问题都是由全局变量及静态变量引起的。 若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。 什么是自旋锁？自旋锁 是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。获取锁的线程一直处于活跃状态，但是并没有执行任何有效的任务，使用这种锁会造成busy-waiting。 它是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。 Java如何实现自旋锁1234567891011121314public class SpinLock &#123; private AtomicReference&lt;Thread&gt; cas = new AtomicReference&lt;Thread&gt;(); public void lock() &#123; Thread current = Thread.currentThread(); // 利用CAS while (!cas.compareAndSet(null, current)) &#123; // DO nothing &#125; &#125; public void unlock() &#123; Thread current = Thread.currentThread(); cas.compareAndSet(current, null); &#125;&#125; lock() 方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。 自旋锁优缺点 缺点 如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。 上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。 优点 自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快 非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能） 可重入的自旋锁和不可重入的自旋锁上面那段代码，仔细分析一下就可以看出，它是不支持重入的，即当一个线程第一次已经获取到了该锁，在锁释放之前又一次重新获取该锁，第二次就不能成功获取到。由于不满足CAS，所以第二次获取会进入while循环等待，而如果是可重入锁，第二次也是应该能够成功获取到的。 而且，即使第二次能够成功获取，那么当第一次释放锁的时候，第二次获取到的锁也会被释放，而这是不合理的。 为了实现可重入锁，我们需要引入一个计数器，用来记录获取锁的线程数。 12345678910111213141516171819202122232425public class ReentrantSpinLock &#123; private AtomicReference&lt;Thread&gt; cas = new AtomicReference&lt;Thread&gt;(); private int count; public void lock() &#123; Thread current = Thread.currentThread(); if (current == cas.get()) &#123; // 如果当前线程已经获取到了锁，线程数增加一，然后返回 count++; return; &#125; // 如果没获取到锁，则通过CAS自旋 while (!cas.compareAndSet(null, current)) &#123; // DO nothing &#125; &#125; public void unlock() &#123; Thread cur = Thread.currentThread(); if (cur == cas.get()) &#123; if (count &gt; 0) &#123;// 如果大于0，表示当前线程多次获取了该锁，释放锁通过count减一来模拟 count--; &#125; else &#123;// 如果count==0，可以将锁释放，这样就能保证获取锁的次数与释放锁的次数是一致的了。 cas.compareAndSet(cur, null); &#125; &#125; &#125;&#125; 自旋锁与互斥锁 自旋锁与互斥锁都是为了实现保护资源共享的机制。 无论是自旋锁还是互斥锁，在任意时刻，都最多只能有一个保持者。 获取互斥锁的线程，如果锁已经被占用，则该线程将进入睡眠状态；获取自旋锁的线程则不会睡眠，而是一直循环等待锁释放。 总结 自旋锁：线程获取锁的时候，如果锁被其他线程持有，则当前线程将循环等待，直到获取到锁。 自旋锁等待期间，线程的状态不会改变，线程一直是用户态并且是活动的(active)。 自旋锁如果持有锁的时间太长，则会导致其它等待获取锁的线程耗尽CPU。 自旋锁本身无法保证公平性，同时也无法保证可重入性。 基于自旋锁，可以实现具备公平性和可重入性质的锁。 参考： https://segmentfault.com/a/1190000015795906#articleHeader0 什么是Java内存模型？ VM包括两个子系统和两个组件。 两个子系统： Class loader（类装载）根据给定的全限定名类名(如：java.lang.Object)来装载class文件到Runtime data area中的method area。程序中可以extends java.lang.ClassLoader类来实现自己的Class loader。 Execution engine（执行引擎）执行classes中的指令。任何JVM specification实现(JDK)的核心都是Execution engine，不同的JDK例如Sun的JDK和IBM的JDK好坏主要就取决于他们各自实现的Execution engine的好坏。 两个组件 Native interface(本地接口)与native libraries交互，是其它编程语言交互的接口。当调用native方法的时候，就进入了一个全新的并且不再受虚拟机限制的世界，所以也很容易出现JVM无法控制的native heap OutOfMemory。 Runtime data area（运行时数据区）这就是我们常说的JVM的内存。主要分为五个部分： 方法区 有时候也成为永久代，在该区内很少发生垃圾回收，但是并不代表不发生GC，在这里进行的GC主要是对方法区里的常量池和对类型的卸载 方法区主要用来存储已被虚拟机加载的类的信息、常量、静态变量和即时编译器编译后的代码等数据，方法区也称持久代（Permanent Generation）。 该区域是被线程共享的。 方法区里有一个运行时常量池，用于存放静态编译产生的字面量和符号引用。该常量池具有动态性，也就是说常量并不一定是编译时确定，运行时生成的常量也会存在这个常量池中。 虚拟机栈 虚拟机栈也就是我们平常所称的栈内存, 它为java方法服务，每个方法在执行的时候都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接和方法出口等信息。 虚拟机栈是线程私有的，它的生命周期与线程相同。 局部变量表里存储的是基本数据类型、returnAddress类型（指向一条字节码指令的地址）和对象引用，这个对象引用有可能是指向对象起始地址的一个指针，也有可能是代表对象的句柄或者与对象相关联的位置。局部变量所需的内存空间在编译器间确定 操作数栈的作用主要用来存储运算结果以及运算的操作数，它不同于局部变量表通过索引来访问，而是压栈和出栈的方式 每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接. 动态链接就是将常量池中的符号引用在运行期转化为直接引用 可通过参数-Xss设置栈容量 本地方法栈本地方法栈和虚拟机栈类似，只不过本地方法栈为Native方法服务 堆 Java堆是所有线程所共享的一块内存，在虚拟机启动时创建 Java堆唯一的目的是存放对象实例，几乎所有的对象实例和数组都在这里创建，因此该区域经常发生垃圾回收操作 可通过参数 -Xms 和-Xmx设置 Java堆为了便于更好的回收和分配内存，可以细分为：新生代和老年代； 新生代：包括Eden区、From Survivor区、To Survivor区，系统默认大小Eden:Survivor=8:1。 老年代：在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 程序计数器内存空间小，字节码解释器工作时通过改变这个计数值可以选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理和线程恢复等功能都需要依赖这个计数器完成。该内存区域是唯一一个java虚拟机规范没有规定任何OOM情况的区域 什么是CAS？介绍CAS算法 即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。 CAS 不通过JVM，直接利用java本地方 JNI（Java Native Interface为JAVA本地调用），直接调用CPU 的cmpxchg（汇编指令）指令。利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法,实现原子操作。其它原子操作都是利用类似的特性完成的。 整个java.util.concurrent都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。 CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS优点确保对内存的读-改-写操作都是原子操作执行 CAS缺点CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大和只能保证一个共享变量的原子操作 总结 使用CAS在线程冲突严重时，会大幅降低程序性能；CAS只适合于线程冲突较少的情况使用。 synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 什么是乐观锁和悲观锁？悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中 synchronized和 ReentrantLock等独占锁就是悲观锁思想的实现。 乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中 java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 使用场景 乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。 悲观锁就比较合适多写的场景。多写的情况，一般会经常产生冲突，如果使用乐观锁，就会导致上层应用会不断的进行retry，这样反倒是降低了性能。 乐观锁常见的两种实现方式 乐观锁一般会使用版本号机制或CAS算法实现。 版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 举一个简单的例子：假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。 1. 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。 1. 在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。 2. 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。 3. 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。 CAS算法即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。 乐观锁的缺点 1 ABA 问题如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。 JDK 1.5 以后的 AtomicStampedReference类就提供了此种能力，其中的 compareAndSet方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 2 循环时间长开销大自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 3 只能保证一个共享变量的原子操作CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了 AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用 AtomicReference类把多个共享变量合并成一个共享变量来操作。 CAS与synchronized的使用情景 简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多） 对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 *和 *轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 什么是AQS？简介AbstractQueuedSynchronizer简称AQS，是一个用于构建锁和同步容器的框架。事实上concurrent包内许多类都是基于AQS构建，例如ReentrantLock，Semaphore，CountDownLatch，ReentrantReadWriteLock，FutureTask等。AQS解决了在实现同步容器时设计的大量细节问题。 AQS使用一个FIFO的队列表示排队等待锁的线程，队列头节点称作“哨兵节点”或者“哑节点”，它不与任何线程关联。其他的节点与等待线程关联，每个节点维护一个等待状态waitStatus。 CAS 原子操作在concurrent包的实现参考 https://blog.52itstyle.com/archives/948/ 由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式： A线程写volatile变量，随后B线程读这个volatile变量。 A线程写volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。 Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。 如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式： 首先，声明共享变量为volatile； 然后，使用CAS的原子条件更新来实现线程之间的同步； 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。 AQS，非阻塞数据结构和原子变量类（Java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下： AQS实现AQS没有锁之类的概念，它有个state变量，是个int类型，在不同场合有着不同含义。 AQS围绕state提供两种基本操作“获取”和“释放”，有条双向队列存放阻塞的等待线程，并提供一系列判断和处理方法，简单说几点： state是独占的，还是共享的； state被获取后，其他线程需要等待； state被释放后，唤醒等待线程； 线程等不及时，如何退出等待。 至于线程是否可以获得state，如何释放state，就不是AQS关心的了，要由子类具体实现。 例如ReentrantLocky用它表示线程重入锁的次数，Semaphore用它表示剩余的许可数量，FutureTask用它表示任务的状态。对state变量值的更新都采用CAS操作保证更新操作的原子性。 AbstractQueuedSynchronizer继承了AbstractOwnableSynchronizer，这个类只有一个变量：exclusiveOwnerThread，表示当前占用该锁的线程，并且提供了相应的get，set方法。 什么是原子操作？在Java Concurrent API中有哪些原子类(atomic classes)？原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。 Atomic包一共提供了13个类，包含四种类型的原子更新方式，分别是： 基本类型 AtomicBoolean AtomicInteger AtomicLong 数组类型 AtomicIntegerArray AtomicLongArray AtomicReferenceArray 引用类型 AtomicReference AtomicReferenceFieldUpdater AtomicMarkableReference 属性类型 AtomicIntegeFeildUpdater AtomicLongFieldUpdater AtomicStampedRefernce 什么是Executors框架？Executor框架同java.util.concurrent.Executor 接口在Java 5中被引入，是一个静态工具类。Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。 无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。 利用Executors框架可以非常方便的创建一个线程池，Java通过Executors提供四种线程池，分别为： newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？什么是阻塞队列？阻塞队列是一个在队列基础上又支持了两个附加操作的队列。 2个附加操作： 支持阻塞的插入方法队列满时，队列会阻塞插入元素的线程，直到队列不满。 支持阻塞的移除方法队列空时，获取元素的线程会等待队列变为非空。 几个关键方法在阻塞队列不可用的时候，上述2个附加操作提供了四种处理方法 方法/处理方式 抛出异常 返回特殊值 一直阻塞 超时退出 插入方法 add(e) offer(e) put(e) offer(e,time,unit) 移除方法 remove() poll() take() poll(time,unit) 检查方法 element() peek() 不可用 不可用 阻塞队列的应用场景阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。简而言之，阻塞队列是生产者用来存放元素、消费者获取元素的容器。 java里的阻塞队列JDK 7 提供了7个阻塞队列，如下 1、ArrayBlockingQueue 数组结构组成的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序，但是默认情况下不保证线程公平的访问队列，即如果队列满了，那么被阻塞在外面的线程对队列访问的顺序是不能保证线程公平（即先阻塞，先插入）的。 2、LinkedBlockingQueue一个由链表结构组成的有界阻塞队列此队列按照先出先进的原则对元素进行排序 3、PriorityBlockingQueue支持优先级的无界阻塞队列 4、DelayQueue支持延时获取元素的无界阻塞队列，即可以指定多久才能从队列中获取当前元素 5、SynchronousQueue不存储元素的阻塞队列，每一个put必须等待一个take操作，否则不能继续添加元素。并且他支持公平访问队列。 6、LinkedTransferQueue由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，多了tryTransfer和transfer方法 transfer方法如果当前有消费者正在等待接收元素（take或者待时间限制的poll方法），transfer可以把生产者传入的元素立刻传给消费者。如果没有消费者等待接收元素，则将元素放在队列的tail节点，并等到该元素被消费者消费了才返回。 tryTransfer方法用来试探生产者传入的元素能否直接传给消费者。如果没有消费者在等待，则返回false。和上述方法的区别是该方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。 7、LinkedBlockingDeque链表结构的双向阻塞队列，优势在于多线程入队时，减少一半的竞争。 什么是Callable和Future? Callable 和 Future 是比较有趣的一对组合。当我们需要获取线程的执行结果时，就需要用到它们。Callable用于产生结果，Future用于获取结果。 Callable接口使用泛型去定义它的返回类型。Executors类提供了一些有用的方法去在线程池中执行Callable内的任务。由于Callable任务是并行的，必须等待它返回的结果。java.util.concurrent.Future对象解决了这个问题。 在线程池提交Callable任务后返回了一个Future对象，使用它可以知道Callable任务的状态和得到Callable返回的执行结果。Future提供了get()方法，等待Callable结束并获取它的执行结果。 什么是FutureTask?FutureTask可用于异步获取执行结果或取消执行任务的场景。通过传入Runnable或者Callable的任务给FutureTask，直接调用其run方法或者放入线程池执行，之后可以在外部通过FutureTask的get方法异步获取执行结果。 FutureTask非常适合用于耗时的计算，主线程可以在完成自己的任务后，再去获取结果。 FutureTask还可以确保即使调用了多次run方法，它都只会执行一次Runnable或者Callable任务，或者通过cancel取消FutureTask的执行等。 高并发场景示例：FutureTask在高并发环境下确保任务只执行一次 在很多高并发的环境下，往往我们只需要某些任务只执行一次。这种使用情景FutureTask的特性恰能胜任。举一个例子，假设有一个带key的连接池，当key存在时，即直接返回key对应的对象；当key不存在时，则创建连接。对于这样的应用场景，通常采用的方法为使用一个Map对象来存储key和连接池对应的对应关系，典型的代码如下面所示： 12345678910111213141516171819202122private Map&lt;String, Connection&gt; connectionPool = new HashMap&lt;String, Connection&gt;();private ReentrantLock lock = new ReentrantLock();public Connection getConnection(String key) &#123; try &#123; lock.lock(); if (connectionPool.containsKey(key)) &#123; return connectionPool.get(key); &#125; else &#123; //创建 Connection Connection conn = createConnection(); connectionPool.put(key, conn); return conn; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; //创建Connection private Connection createConnection() &#123; return null;&#125; 在上面的例子中，我们通过加锁确保高并发环境下的线程安全，也确保了connection只创建一次，然而确牺牲了性能。改用ConcurrentHash的情况下，几乎可以避免加锁的操作，性能大大提高，但是在高并发的情况下有可能出现Connection被创建多次的现象。这时最需要解决的问题就是当key不存在时，创建Connection的动作能放在connectionPool之后执行，这正是FutureTask发挥作用的时机，基于ConcurrentHashMap和FutureTask的改造代码如下： 123456789101112131415161718192021222324252627282930private ConcurrentHashMap&lt;String, FutureTask&lt;Connection&gt;&gt; connectionPool = new ConcurrentHashMap&lt;String, FutureTask&lt;Connection&gt;&gt;();public Connection getConnection(String key) throws Exception &#123; FutureTask&lt;Connection&gt; connectionTask = connectionPool.get(key); if (connectionTask != null) &#123; return connectionTask.get(); &#125; else &#123; Callable&lt;Connection&gt; callable = new Callable&lt;Connection&gt;() &#123; @Override public Connection call() throws Exception &#123; // TODO Auto-generated method stub return createConnection(); &#125; &#125;; FutureTask&lt;Connection&gt; newTask = new FutureTask&lt;Connection&gt;(callable); connectionTask = connectionPool.putIfAbsent(key, newTask); if (connectionTask == null) &#123; connectionTask = newTask; connectionTask.run(); &#125; return connectionTask.get(); &#125;&#125;//创建Connectionprivate Connection createConnection() &#123; return null;&#125; 经过这样的改造，可以避免由于并发带来的多次创建连接及锁的出现。 什么是同步容器和并发容器的实现？一、同步容器主要代表有Vector和HashTable，以及Collections.synchronizedXxx等。 锁的粒度为当前对象整体。 迭代器是及时失败的，即在迭代的过程中发现被修改，就会抛出ConcurrentModificationException。 二、并发容器主要代表有ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentSkipListMap、ConcurrentSkipListSet。 锁的粒度是分散的、细粒度的，即读和写是使用不同的锁。 迭代器具有弱一致性，即可以容忍并发修改，不会抛出ConcurrentModificationException。 ConcurrentHashMap采用分离锁技术，同步容器中，是一个容器一个锁，但在ConcurrentHashMap中，会将hash表的数组部分分成若干段，每段维护一个锁，以达到高效的并发访问； 三、阻塞队列主要代表有LinkedBlockingQueue、ArrayBlockingQueue、PriorityBlockingQueue(Comparable, Comparator)、SynchronousQueue。 提供了可阻塞的put和take方法，以及支持定时的offer和poll方法。 适用于生产者、消费者模式（线程池和工作队列-Executor），同时也是同步容器 四、双端队列主要代表有ArrayDeque和LinkedBlockingDeque。意义：正如阻塞队列适用于生产者消费者模式，双端队列同样适用与另一种模式，即工作密取。在生产者-消费者设计中，所有消费者共享一个工作队列，而在工作密取中，每个消费者都有各自的双端队列。 如果一个消费者完成了自己双端队列中的全部工作，那么他就可以从其他消费者的双端队列末尾秘密的获取工作。具有更好的可伸缩性，这是因为工作者线程不会在单个共享的任务队列上发生竞争。 在大多数时候，他们都只是访问自己的双端队列，从而极大的减少了竞争。当工作者线程需要访问另一个队列时，它会从队列的尾部而不是头部获取工作，因此进一步降低了队列上的竞争。 适用于：网页爬虫等任务中 五、比较及适用场景 如果不需要阻塞队列，优先选择ConcurrentLinkedQueue； 如果需要阻塞队列，队列大小固定优先选择ArrayBlockingQueue，队列大小不固定优先选择LinkedBlockingQueue； 如果需要对队列进行排序，选择PriorityBlockingQueue； 如果需要一个快速交换的队列，选择SynchronousQueue； 如果需要对队列中的元素进行延时操作，则选择DelayQueue。 什么是多线程？优缺点？多线程：是指从软件或者硬件上实现多个线程的并发技术。 多线程的好处：使用多线程可以把程序中占据时间长的任务放到后台去处理，如图片、视屏的下载发挥多核处理器的优势，并发执行让系统运行的更快、更流畅，用户体验更好 多线程的缺点： 大量的线程降低代码的可读性； 更多的线程需要更多的内存空间 当多个线程对同一个资源出现争夺时候要注意线程安全的问题。 什么是多线程的上下文切换？即使是单核CPU也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程时同时执行的，时间片一般是几十毫秒（ms） 上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。 CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态。 从任务保存到再加载的过程就是一次上下文切换。 ThreadLocal的设计理念与作用？Java中的ThreadLocal类允许我们创建只能被同一个线程读写的变量。因此，如果一段代码含有一个ThreadLocal变量的引用，即使两个线程同时执行这段代码，它们也无法访问到对方的ThreadLocal变量 InheritableThreadLocal 1public static ThreadLocal&lt;Integer&gt; threadLocal = new InheritableThreadLocal&lt;Integer&gt;(); InheritableThreadLocal类是ThreadLocal类的子类。ThreadLocal中每个线程拥有它自己的值，与ThreadLocal不同的是，InheritableThreadLocal允许一个线程以及该线程创建的所有子线程都可以访问它保存的值。 ThreadPool（线程池）用法与优势？为什么要用线程池: 减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。 可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。 减少在创建和销毁线程上所花的时间以及系统资源的开销,如不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存 Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。 new Thread 缺点 每次new Thread新建对象性能差。 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。 缺乏更多功能，如定时执行、定期执行、线程中断。 Executors提供四种线程池 newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 ThreadPoolExecutor的构造函数123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 参数： corePoolSize核心线程数大小，当线程数&lt;corepoolsize ，会创建线程执行 maximumPoolSize 最大线程数， 当线程数 &gt;= corePoolSize的时候，会把runnable放入workQueue中 keepAliveTime 保持存活时间，当线程数大于corePoolSize的空闲线程能保持的最大时间。 unit 时间单位 workQueue 保存任务的阻塞队列 threadFactory 创建线程的工厂 handler 拒绝策略 任务执行顺序： 当线程数小于corePoolSize时，创建线程执行任务。 当线程数大于等于corePoolSize并且workQueue没有满时，放入workQueue中 线程数大于等于corePoolSize并且当workQueue满时，新任务新建线程运行，线程总数要小于maximumPoolSize 当线程总数等于maximumPoolSize并且workQueue满了的时候执行handler的rejectedExecution。也就是拒绝策略。 ThreadPoolExecutor默认有四个拒绝策略： ThreadPoolExecutor.AbortPolicy() 直接抛出异常RejectedExecutionException ThreadPoolExecutor.CallerRunsPolicy() 直接调用run方法并且阻塞执行 ThreadPoolExecutor.DiscardPolicy() 直接丢弃后来的任务 ThreadPoolExecutor.DiscardOldestPolicy() 丢弃在队列中队首的任务 当然可以自己继承 RejectedExecutionHandler 来写拒绝策略. Synchronized和ReentrantLock的区别？java在编写多线程程序时，为了保证线程安全，需要对数据同步，经常用到两种同步方式就是Synchronized和重入锁ReentrantLock。 基础知识 可重入锁可重入锁是指同一个线程可以多次获取同一把锁。ReentrantLock和synchronized都是可重入锁。 可中断锁可中断锁是指线程尝试获取锁的过程中，是否可以响应中断。synchronized是不可中断锁，而ReentrantLock则提供了中断功能。 公平锁与非公平锁公平锁是指多个线程同时尝试获取同一把锁时，获取锁的顺序按照线程达到的顺序，而非公平锁则允许线程“插队”。synchronized是非公平锁，而ReentrantLock的默认实现是非公平锁，但是也可以设置为公平锁。 CAS操作(CompareAndSwap)CAS操作简单的说就是比较并交换。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。” Synchronizedsynchronized是java内置的关键字，它提供了一种独占的加锁方式。synchronized的获取和释放锁由JVM实现，用户不需要显示的释放锁，非常方便。然而synchronized也有一定的局限性 例如： 当线程尝试获取锁的时候，如果获取不到锁会一直阻塞； 如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。 ReentrantLockReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。 用法示例： 12345678910private Lock lock = new ReentrantLock();public void test() &#123; lock.lock(); try &#123; doSomeThing(); &#125; finally &#123; lock.unlock(); &#125;&#125; lock() 如果获取了锁立即返回，如果别的线程持有锁，当前线程则一直处于休眠状态，直到获取锁 tryLock() 如果获取了锁立即返回true，如果别的线程正持有锁，立即返回false； tryLock(long timeout,TimeUnit unit) 如果获取了锁定立即返回true，如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false； lockInterruptibly 如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断 ReentrantLock特性 等待可中断避免，出现死锁的情况（如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false） 公平锁与非公平锁多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好 ReenTrantLock实现的原理：简单来说，ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。 总结在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁) 后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。 Synchronized： 在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好。 ReentrantLock: ReentrantLock用起来会复杂一些。在基本的加锁和解锁上，两者是一样的，所以无特殊情况下，推荐使用synchronized。ReentrantLock的优势在于它更灵活、更强大，增加了轮训、超时、中断等高级功能。 ReentrantLock默认使用非公平锁是基于性能考虑，公平锁为了保证线程规规矩矩地排队，需要增加阻塞和唤醒的时间开销。如果直接插队获取非公平锁，跳过了对队列的处理，速度会更快。 Semaphore有什么作用？Semaphore就是一个信号量，它的作用是限制某段代码块的并发数。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。 由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。 1234567891011121314151617// 阻塞// 用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可public void acquire() throws InterruptedException;// 用来释放许可。注意，在释放许可之前，必须先获获得许可public void release(); // 非阻塞//尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回false public boolean tryAcquire() &#123;&#125;; //尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false public boolean tryAcquire(long timeout , TimeUnit unit ) throws InterruptedException &#123;&#125;; //尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回false public boolean tryAcquire(int permits ) &#123;&#125;; //尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true public boolean tryAcquire(int permits , long timeout , TimeUnit unit ) throws InterruptedException &#123;&#125;; //得到当前可用的许可数目 public int availablePermits(); 示例:假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现： 12345678910111213141516171819202122232425262728293031323334public class Test&#123; public static void main(String[] args) &#123; int N = 8 ; //工人数 Semaphore semaphore = new Semaphore(5); //机器数目 for (int i = 0; i &lt; N; i++) &#123; new Worker(i, semaphore ).start (); &#125; static class Worker extends Thread &#123; private int num; private Semaphore semaphore; public Worker(int num, Semaphore semaphore)&#123; this.num = num; this.semaphore = semaphore; &#125; @Override public void run() &#123; try &#123; semaphore.acquire(); System.out.println ("工人"+ this.num + "占用一个机器在生产..."); Thread.sleep (2000 ); System.out.println ("工人"+ this.num + "释放出机器"); semaphore.release (); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。 它的优势有： 可以使锁更公平 可以使线程在等待锁的时候响应中断 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间 可以在不同的范围，以不同的顺序获取和释放锁 ReentrantReadWriteLock读写锁的使用？Lock比传统线程模型中的synchronized方式更加面向对象，与生活中的锁类似，锁本身也应该是一个对象。两个线程执行的代码片段要实现同步互斥的效果，它们必须用同一个Lock对象。 读写锁：分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可。 如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁；如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！ ReentrantReadWriteLock会使用两把锁来解决问题，一个读锁，一个写锁 线程进入读锁的前提条件： 没有其他线程的写锁 没有写请求或者有写请求，但调用线程和持有锁的线程是同一个 线程进入写锁的前提条件： 没有其他线程的读锁 没有其他线程的写锁 注意点： 读锁的重入是允许多个申请读操作的线程的，而写锁同时只允许单个线程占有，该线程的写操作可以重入。 如果一个线程占有了写锁，在不释放写锁的情况下，它还能占有读锁，即写锁降级为读锁。 对于同时占有读锁和写锁的线程，如果完全释放了写锁，那么它就完全转换成了读锁，以后的写操作无法重入，在写锁未完全释放时写操作是可以重入的。 公平模式下无论读锁还是写锁的申请都必须按照AQS锁等待队列先进先出的顺序。非公平模式下读操作插队的条件是锁等待队列head节点后的下一个节点是SHARED型节点，写锁则无条件插队。 读锁不允许newConditon获取Condition接口，而写锁的newCondition接口实现方法同ReentrantLock。 CyclicBarrier和CountDownLatch的用法及区别？ CountDownLatch CyclicBarrier 减计数方式 加计数方式 计算为0时释放所有等待的线程 计数达到指定值时释放所有等待线程 计数为0时，无法重置 计数达到指定值时，计数置为0重新开始 调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响 调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞 不可重复利用 可重复利用 LockSupport工具？1、LockSupport基本介绍与基本使用LockSupport是JDK中比较底层的类，用来创建锁和其他同步工具类的基本线程阻塞。java锁和同步器框架的核心 AQS: AbstractQueuedSynchronizer，就是通过调用 LockSupport .park()和 LockSupport .unpark()实现线程的阻塞和唤醒 的。 LockSupport 很类似于二元信号量(只有1个许可证可供使用)，如果这个许可还没有被占用，当前线程获取许可并继 续 执行；如果许可已经被占用，当前线 程阻塞，等待获取许可。 全部操作： park()/park(Object)等待通行准许。 parkNanos(long)/parkNanos(Object, long)在指定运行时间（即相对时间）内，等待通行准许。 parkUntil(long)/parkUntil(Object, long)在指定到期时间（即绝对时间）内，等待通行准许。 unpark(Thread)发放通行准许或提前发放。（注：不管提前发放多少次，只用于一次性使用。） getBlocker(Thread)进入等待通行准许时，所提供的对象。 主要用途：当前线程需要唤醒另一个线程，但是只确定它会进入阻塞，但不确定它是否已经进入阻塞，因此不管是否已经进入阻塞，还是准备进入阻塞，都将发放一个通行准许。 Condition接口及其实现原理？ 在java.util.concurrent包中，有两个很特殊的工具类，Condition和ReentrantLock，使用过的人都知道，ReentrantLock（重入锁）是jdk的concurrent包提供的一种独占锁的实现 我们知道在线程的同步时可以使一个线程阻塞而等待一个信号，同时放弃锁使其他线程可以能竞争到锁在synchronized中我们可以使用Object的wait()和notify方法实现这种等待和唤醒 但是在Lock中怎么实现这种wait和notify呢？答案是Condition，学习Condition主要是为了方便以后学习blockqueue和concurrenthashmap的源码，同时也进一步理解ReentrantLock。Condition是一个多线程间协调通信的工具类，使得某个，或者某些线程一起等待某个条件（Condition）,只有当该条件具备( signal 或者 signalAll方法被带调用)时 ，这些等待线程才会被唤醒，从而重新争夺锁。 Fork/Join框架的理解?Oracle的官方给出的定义是：Fork/Join框架是一个实现了ExecutorService接口的多线程处理器。它可以把一个大的任务划分为若干个小的任务并发执行，充分利用可用的资源，进而提高应用的执行效率。 我们再通过Fork和Join这两个单词来理解下Fork/Join框架，Fork就是把一个大任务切分为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。 工作窃取算法工作窃取算法是指线程从其他任务队列中窃取任务执行（可能你会很诧异，这个算法有什么用。待会你就知道了）。 考虑下面这种场景：有一个很大的计算任务，为了减少线程的竞争，会将这些大任务切分为小任务并分在不同的队列等待执行，然后为每个任务队列创建一个线程执行队列的任务。那么问题来了，有的线程可能很快就执行完了，而其他线程还有任务没执行完，执行完的线程与其空闲下来不如帮助其他线程执行任务，这样也能加快执行进程。所以，执行完的空闲线程从其他队列的尾部窃取任务执行，而被窃取任务的线程则从队列的头部取任务执行（这里使用了双端队列，既不影响被窃取任务的执行过程又能加快执行进度）。 从以上的介绍中，能够发现工作窃取算法的优点是充分利用线程提高并行执行的进度。当然缺点是在某些情况下仍然存在竞争，比如双端队列只有一个任务需要执行的时候 使用Fork/Join框架两步： 分割任务：首先需要创建一个ForkJoin任务，执行该类的fork方法可以对任务不断切割，直到分割的子任务足够小 合并任务执行结果：子任务执行的结果同一放在一个队列中，通过启动一个线程从队列中取执行结果。 Fork/Join实现了ExecutorService，所以它的任务也需要放在线程池中执行。它的不同在于它使用了工作窃取算法，空闲的线程可以从满负荷的线程中窃取任务来帮忙执行。 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.concurrent.ExecutionException;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.ForkJoinTask;import java.util.concurrent.RecursiveTask;public class CountTask extends RecursiveTask&lt;Integer&gt;&#123; //阈值 private static final int THRESHOLD = 2; //起始值 private int start; //结束值 private int end; public CountTask(int start, int end) &#123; this.start = start; this.end = end; &#125; @Override protected Integer compute() &#123; boolean compute = (end - start) &lt;= THRESHOLD; int res = 0; if (compute)&#123; for (int i = start; i &lt;= end; i++)&#123; res += i; &#125; &#125;else &#123; //如果长度大于阈值，则分割为小任务 int mid = (start + end) / 2; CountTask task1 = new CountTask(start,mid); CountTask task2 = new CountTask(mid + 1, end); //计算小任务的值 task1.fork(); task2.fork(); //得到两个小任务的值 int task1Res = task1.join(); int task2Res = task2.join(); res = task1Res + task2Res; &#125; return res; &#125; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ForkJoinPool pool = new ForkJoinPool(); CountTask task = new CountTask(1,5); ForkJoinTask&lt;Integer&gt; submit = pool.submit(task); System.out.println("Final result:" + submit.get()); &#125;&#125; 代码中使用了FokJoinTask，其与一般任务的区别在于它需要实现compute方法，在方法需要判断任务是否在阈值区间内，如果不是则需要把任务切分到足够小，直到能够进行计算。 每个被切分的子任务又会重新进入compute方法，再继续判断是否需要继续切分，如果不需要则直接得到子任务执行的结果，如果需要的话则继续切分，如此循环，直到调用join方法得到最终的结果。 wait()和sleep()的区别? sleep() 方法是线程类（Thread）的静态方法，让调用线程进入睡眠状态，让出执行机会给其他线程，等到休眠时间结束后，线程进入就绪状态和其他线程一起竞争cpu的执行时间。 因为sleep() 是static静态的方法，他不能改变对象的机锁，当一个synchronized块中调用了sleep() 方法，线程虽然进入休眠，但是对象的机锁没有被释放，其他线程依然无法访问这个对象。 wait()wait()是Object类的方法，当一个线程执行到wait方法时，它就进入到一个和该对象相关的等待池，同时释放对象的机锁，使得其他线程能够访问，可以通过notify，notifyAll方法来唤醒等待的线程 线程的五个状态（五种状态，创建、就绪、运行、阻塞和死亡）? start()方法和run()方法的区别？每个线程都是通过某个特定Thread对象所对应的方法run()来完成其操作的，方法run()称为线程体。通过调用Thread类的start()方法来启动一个线程。 start()启动一个线程，真正实现了多线程运行。这时无需等待run方法体代码执行完毕，可以直接继续执行下面的代码；这时此线程是处于就绪状态， 并没有运行。 然后通过此Thread类调用方法run()来完成其运行状态， 这里方法run()称为线程体，它包含了要执行的这个线程的内容， Run方法运行结束， 此线程终止。然后CPU再调度其它线程。 run()方法是在本线程里的，只是线程里的一个函数,而不是多线程的。如果直接调用run(),其实就相当于是调用了一个普通函数而已，直接待用run()方法必须等待run()方法执行完毕才能执行下面的代码，所以执行路径还是只有一条，根本就没有线程的特征，所以在多线程执行时要使用start()方法而不是run()方法。 Runnable接口和Callable接口的区别？ Runnable接口中的run()方法的返回值是void，它做的事情只是纯粹地去执行run()方法中的代码而已； Callable接口中的call()方法是有返回值的，是一个泛型，和Future、FutureTask配合可以用来获取异步执行的结果。 Callable+Future/FutureTask却可以获取多线程运行的结果，可以在等待时间太长没获取到需要的数据的情况下取消该线程的任务，非常有用。 volatile关键字的作用？volatile关键字的作用主要有两个： （1）多线程主要围绕可见性和原子性两个特性而展开，使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据; （2）代码底层执行是Java代码–&gt;字节码–&gt;根据字节码执行对应的C/C++代码–&gt;C/C++代码被编译成汇编语言–&gt;和硬件电路交互，现实中，为了获取更好的性能JVM可能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止语义重排序，当然这也一定程度上降低了代码执行效率; 从实践角度而言，volatile的一个重要作用就是和CAS结合，保证了原子性. Java中如何获取到线程dump文件？死循环、死锁、阻塞、页面打开慢等问题，打线程dump是最好的解决问题的途径。所谓线程dump也就是线程堆栈，获取到线程堆栈有两步： （1）获取到线程的pid，可以通过使用jps命令，在Linux环境下还可以使用ps -ef | grep java （2）打印线程堆栈，可以通过使用jstack pid命令，在Linux环境下还可以使用kill -3 pid 另外提一点，Thread类提供了一个getStackTrace()方法也可以用于获取线程堆栈。这是一个实例方法，因此此方法是和具体线程实例绑定的，每次获取获取到的是具体某个线程当前运行的堆栈， 线程和进程有什么区别？ 进程是系统进行资源分配的基本单位，有独立的内存地址空间 线程是CPU独立运行和独立调度的基本单位，没有单独地址空间，有独立的栈，局部变量，寄存器， 程序计数器等。 创建进程的开销大，包括创建虚拟地址空间等需要大量系统资源 创建线程开销小，基本上只有一个内核对象和一个堆栈。 一个进程无法直接访问另一个进程的资源；同一进程内的多个线程共享进程的资源。 进程切换开销大，线程切换开销小；进程间通信开销大，线程间通信开销小。 线程属于进程，不能独立执行。每个进程至少要有一个线程，成为主线程 线程实现的方式有几种（四种）？ 继承Thread类，重写run方法 实现Runnable接口，重写run方法，实现Runnable接口的实现类的实例对象作为Thread构造函数的target 实现Callable接口通过FutureTask包装器来创建Thread线程 1FutureTask&lt;Object&gt; oneTask = new FutureTask&lt;Object&gt;(oneCallable); 通过线程池创建线程 12ExecutorService executorService = Executors.newFixedThreadPool(5);executorService.execute(new RunnableTask()); 高并发、任务执行时间短的业务怎样使用线程池？并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？ （1）高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换 （2）并发不高、任务执行时间长的业务要区分开看： a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以加大线程池中的线程数目，让CPU处理更多的业务 b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换 （3）并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考（2）。最后，业务执行时间长的问题，也可能需要分析一下，看看能不能使用中间件对任务进行拆分和解耦。 锁的等级：方法锁、对象锁、类锁?1. 通过在方法声明中加入 synchronized关键字来声明 synchronized 方法 synchronized 方法控制对类成员变量的访问：每个类实例对应一把锁，每个 synchronized 方法都必须获得调用该方法的类实例的锁方能执行，否则所属线程阻塞，方法一旦执行，就独占该锁，直到从该方法返回时才将锁释放，此后被阻塞的线程方能获得该锁，重新进入可执行状态。 这种机制确保了同一时刻对于每一个类实例，其所有声明为 synchronized 的成员函数中至多只有一个处于可执行状态，从而有效避免了类成员变量的访问冲突。 2. 对象锁（synchronized修饰方法或代码块） 当一个对象中有synchronized method或synchronized block的时候调用此对象的同步方法或进入其同步区域时，就必须先获得对象锁。如果此对象的对象锁已被其他调用者占用，则需要等待此锁被释放。（方法锁也是对象锁） java的所有对象都含有1个互斥锁，这个锁由JVM自动获取和释放。线程进入synchronized方法的时候获取该对象的锁，当然如果已经有线程获取了这个对象的锁，那么当前线程会等待；synchronized方法正常返回或者抛异常而终止，JVM会自动释放对象锁。这里也体现了用synchronized来加锁的1个好处，方法抛异常的时候，锁仍然可以由JVM来自动释放。 3. 类锁(synchronized 修饰静态的方法或代码块) 由于一个class不论被实例化多少次，其中的静态方法和静态变量在内存中都只有一份。所以，一旦一个静态的方法被申明为synchronized。此类所有的实例化对象在调用此方法，共用同一把锁，我们称之为类锁。 对象锁是用来控制实例方法之间的同步，类锁是用来控制静态方法（或静态变量互斥体）之间的同步 如果同步块内的线程抛出异常会发生什么？无论你的同步块是正常还是异常退出的，里面的线程都由JVM来自动释放锁，所以对比锁接口我更喜欢同步块，因为它不用我花费精力去释放锁，该功能可以在finally block里释放锁实现。 并发编程（concurrency）并行编程（parallellism）有什么区别？并发和并行是： 解释一：并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔发生。 解释二：并行是在不同实体上的多个事件，并发是在同一实体上的多个事件。 解释三：在一台处理器上“同时”处理多个任务，在多台处理器上同时处理多个任务。如hadoop分布式集群 所以并发编程的目标是充分的利用处理器的每一个核，以达到最高的处理性能。 如何在两个线程之间共享数据? 通过在线程之间共享对象, 然后通过wait/notify/notifyAll、await/signal/signalAll进行唤起和等待，比方说阻塞队列BlockingQueue就是为线程之间共享数据而设计的； Exchanger 用于进行线程间数据交换； 生产者消费者模型的作用是什么?这个问题很理论，但是很重要： （1）通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率，这是生产者消费者模型最重要的作用 （2）解耦，这是生产者消费者模型附带的作用，解耦意味着生产者和消费者之间的联系少，联系越少越可以独自发展而不需要收到相互的制约 怎么唤醒一个阻塞的线程? 如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它； 如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统。 Java中用到的线程调度算法是什么抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。 单例模式的线程安全性?首先要说的是单例模式的线程安全意味着：某个类的实例在多线程环境下只会被创建一次出来。单例模式有很多种的写法，我总结一下： （1）饿汉式单例模式的写法：线程安全 （2）懒汉式单例模式的写法：非线程安全 （3）双检锁单例模式的写法：线程安全 同步方法和同步块，哪个是更好的选择?同步块是更好的选择，因为它不会锁住整个对象（当然也可以让它锁住整个对象）。 同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。 123456789101112131415161718public class SyncObj&#123; // 同步方法会锁住整个对象 public synchronized void showA()&#123; System.out.println("showA.."); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public void showB() &#123; // 同步块 synchronized (this) &#123; System.out.println("showB.."); &#125; &#125;&#125; 如何检测死锁？怎么预防死锁？死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁。通俗地讲就是两个或多个进程被无限期地阻塞、相互等待的一种状态 死锁产生的原因？ 1.因竞争资源发生死锁 现象：系统中供多个进程共享的资源的数目不足以满足全部进程的需要时，就会引起对诸资源的竞争而发生死锁现象 2.进程推进顺序不当发生死锁 死锁的四个必要条件： 互斥条件：进程对所分配到的资源不允许其他进程进行访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源 请求和保持条件：进程获得一定的资源之后，又对其他资源发出请求，但是该资源可能被其他进程占有，此事请求阻塞，但又对自己获得的资源保持不放 不可剥夺条件：是指进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用完后自己释放 环路等待条件：是指进程发生死锁后，若干进程之间形成一种头尾相接的循环等待资源关系这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。 检测死锁有两个容器，一个用于保存线程正在请求的锁，一个用于保存线程已经持有的锁。每次加锁之前都会做如下检测: 检测当前正在请求的锁是否已经被其它线程持有,如果有，则把那些线程找出来 遍历第一步中返回的线程，检查自己持有的锁是否正被其中任何一个线程请求，如果第二步返回真,表示出现了死锁 死锁的解除与预防：理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。 所以，在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确定资源的合理分配算法，避免进程永久占据系统资源。 此外，也要防止进程在处于等待状态的情况下占用资源。因此，对资源的分配要给予合理的规划。 转载：想进大厂？50个多线程面试题，你会多少？（一）想进大厂？50个多线程面试题，你会多少？（二）]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>Java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池ThreadPoolExecutor源码详解]]></title>
    <url>%2F2019%2F07%2F19%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[本文从源码层面去解读下java线程池的实现思想和代码。 总览先看一张java线程池的继承关系图： 简单介绍下： Executor 位于最顶层，也是最简单的，只有一个 execute(Runnable runnable) 接口方法定义 ExecutorService 也是接口，在 Executor 接口的基础上添加了很多的接口方法，很多时候我们使用这个接口就够了 AbstractExecutorService，这是抽象类，这里实现了非常有用的一些方法供子类直接使用，例如: invokeAll()、 invokeAny() ThreadPoolExecutor 类，这个类才是真正的线程池实现，提供了非常丰富的功能。 从图中的方法可以看到，还涉及到一些其他类： 其中： Executors类这个是工具类，里面的方法都是静态方法，如以下我们最常用的用于生成 ThreadPoolExecutor 的实例的一些方法： 123456789101112public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; Future接口由于线程池支持获取线程执行的结果，所以，引入了 Future 接口，RunnableFuture 继承自此接口，然后我们最需要关心的就是它的实现类 FutureTask。 FutureTask类在线程池的使用过程中，我们是往线程池提交任务（task），我们提交的每个任务是实现了 Runnable 接口的，其实就是先将 Runnable 的任务包装成 FutureTask，然后再提交到线程池。它首先是一个任务（Task），然后具有 Future 接口的语义，即可以在将来（Future）得到执行的结果。 BlockingQueue如果线程数达到 corePoolSize，我们的每个任务会提交到等待队列中，等待线程池中的线程来取任务并执行。这里的 BlockingQueue 通常我们使用其实现类 LinkedBlockingQueue、ArrayBlockingQueue 和 SynchronousQueue，每个实现类都有不同的特征. Executor接口1234567/* * @since 1.5 * @author Doug Lea */public interface Executor &#123; void execute(Runnable command);&#125; 可以看到 Executor 接口非常简单，就一个 void execute(Runnable command) 方法，代表提交一个任务。为了理解 java 线程池的整个设计方案，我会按照 Doug Lea 的设计思路来多说一些相关的东西。 我们经常这样启动一个线程： 123new Thread(new Runnable()&#123; // do something&#125;).start(); 用了线程池 Executor 后就可以像下面这么使用： 123Executor executor = anExecutor;executor.execute(new RunnableTask1());executor.execute(new RunnableTask2()); 如果我们希望线程池同步执行每一个任务，我们可以这么实现这个接口： 12345class DirectExecutor implements Executor &#123; public void execute(Runnable r) &#123; r.run(); // 这里不是用的new Thread(r).start()，也就是说没有启动任何一个新的线程。 &#125;&#125; 如果我们希望每个任务提交进来后，直接启动一个新的线程来执行这个任务，我们可以这么实现： 12345class ThreadPerTaskExecutor implements Executor &#123; public void execute(Runnable r) &#123; new Thread(r).start(); // 每个任务都用一个新的线程来执行 &#125;&#125; 我们再来看下怎么组合两个 Executor 来使用，下面这个实现是将所有的任务都加到一个 queue 中，然后从 queue 中取任务，交给真正的执行器执行，这里采用 synchronized 进行并发控制： 12345678910111213141516171819202122232425262728293031323334353637class SerialExecutor implements Executor &#123; // 任务队列 final Queue&lt;Runnable&gt; tasks = new ArrayDeque&lt;Runnable&gt;(); // 这个才是真正的执行器 final Executor executor; // 当前正在执行的任务 Runnable active; // 初始化的时候，指定执行器 SerialExecutor(Executor executor) &#123; this.executor = executor; &#125; // 添加任务到线程池: 将任务添加到任务队列，scheduleNext 触发执行器去任务队列取任务 public synchronized void execute(final Runnable r) &#123; tasks.offer(new Runnable() &#123; public void run() &#123; try &#123; r.run(); &#125; finally &#123; scheduleNext(); &#125; &#125; &#125;); if (active == null) &#123; scheduleNext(); &#125; &#125; protected synchronized void scheduleNext() &#123; if ((active = tasks.poll()) != null) &#123; // 具体的执行转给真正的执行器 executor executor.execute(active); &#125; &#125;&#125; Executor 这个接口只有提交任务的功能，太简单了，我们想要更丰富的功能，比如我们想知道执行结果、我们想知道当前线程池有多少个线程活着、已经完成了多少任务等等，这些都是这个接口的不足的地方。接下来我们要介绍的是继承自 Executor 接口的 ExecutorService 接口，这个接口提供了比较丰富的功能，也是我们最常使用到的接口。 ExecutorService简单初略地来看一下这个接口中都有哪些方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152简单初略地来看一下这个接口中都有哪些方法：public interface ExecutorService extends Executor &#123; // 关闭线程池，已提交的任务继续执行，不接受继续提交新任务 void shutdown(); // 关闭线程池，尝试停止正在执行的所有任务，不接受继续提交新任务 // 它和前面的方法相比，加了一个单词“now”，区别在于它会去停止当前正在进行的任务 List&lt;Runnable&gt; shutdownNow(); // 线程池是否已关闭 boolean isShutdown(); // 如果调用了 shutdown() 或 shutdownNow() 方法后，所有任务结束了，那么返回true // 这个方法必须在调用shutdown或shutdownNow方法之后调用才会返回true boolean isTerminated(); // 等待所有任务完成，并设置超时时间 // 我们这么理解，实际应用中是，先调用 shutdown 或 shutdownNow， // 然后再调这个方法等待所有的线程真正地完成，返回值意味着有没有超时 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; // 提交一个 Callable 任务 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); // 提交一个 Runnable 任务，第二个参数将会放到 Future 中，作为返回值， // 因为 Runnable 的 run 方法本身并不返回任何东西 &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); // 提交一个 Runnable 任务 Future&lt;?&gt; submit(Runnable task); // 执行所有任务，等全部完成后返回 Future 类型的一个 list &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; // 也是执行所有任务，但是这里设置了超时时间 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; // 只要其中的一个任务结束了，就可以返回，返回执行完的那个任务的结果 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; // 同上一个方法，只要其中的一个任务结束了，就可以返回，返回执行完的那个任务的结果， // 不过这个带超时，超过指定的时间，抛出 TimeoutException 异常 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 这些方法都很好理解，一个简单的线程池主要就是这些功能，能提交任务，能获取结果，能关闭线程池，这也是为什么我们经常用这个接口的原因。 FutureTask在继续往下层介绍 ExecutorService 的实现类之前，我们先来说说相关的类 FutureTask。 ![](/images/future_task_ inherit.png) FutureTask 通过 RunnableFuture 间接实现了 Runnable 接口，所以每个 Runnable 通常都先包装成 FutureTask，然后调用 executor.execute(Runnable command) 将其提交给线程池. Runnable 的 void run() 方法是没有返回值的，所以，通常，如果我们需要的话，会在 submit 中指定第二个参数作为返回值： 1&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); 其实到时候会通过这两个参数，将其包装成 Callable。 Callable 也是因为线程池的需要，所以才有了这个接口。它和 Runnable 的区别在于 run() 没有返回值，而 Callable 的 call() 方法有返回值，同时，如果运行出现异常，call() 方法会抛出异常。 123public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; 123public interface Runnable &#123; public abstract void run();&#125; 下面，我们来看看 ExecutorService 的抽象实现 AbstractExecutorService 。 AbstractExecutorServiceAbstractExecutorService 抽象类派生自 ExecutorService 接口，然后在其基础上实现了几个实用的方法，这些方法提供给子类进行调用。 invokeAny方法： invokeAll方法： newTaskFor方法： 用于将任务包装成 FutureTask 定义于最上层接口 Executor中的 void execute(Runnable command) 由于不需要获取结果，不会进行 FutureTask 的包装。 需要获取结果（FutureTask），用 submit 方法，不需要获取结果，可以用 execute 方法。 下面重点讲解下newTaskFor和invokeAny、invokeAll方法源码。 newTaskFor &amp;&amp; submit1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public abstract class AbstractExecutorService implements ExecutorService &#123; /** * RunnableFuture 是用于获取执行结果的，我们常用它的子类 FutureTask * 下面两个 newTaskFor 方法用于将我们的任务包装成 FutureTask 提交到线程池中执行 */ protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; /** * 提交任务 */ public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(); &#125; // 1. 将任务包装成 FutureTask RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); // 2. 交给子类执行器执行 execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) &#123; throw new NullPointerException(); &#125; // 1. 将任务包装成 FutureTask RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); // 2. 交给子类执行器执行 execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) &#123; throw new NullPointerException(); &#125; // 1. 将任务包装成 FutureTask RunnableFuture&lt;T&gt; ftask = newTaskFor(task); // 2. 交给子类执行器执行 execute(ftask); return ftask; &#125;&#125; invokeAny123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122/** * 此方法目的：将 tasks 集合中的任务提交到线程池执行，任意一个线程执行完后就可以结束了 * 第二个参数 timed 代表是否设置超时机制，超时时间为第三个参数， * 如果 timed 为 true，同时超时了还没有一个线程返回结果，那么抛出 TimeoutException 异常 */private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; if (tasks == null) &#123; throw new NullPointerException(); &#125; int ntasks = tasks.size(); if (ntasks == 0) &#123; throw new IllegalArgumentException(); &#125; ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(ntasks); // ExecutorCompletionService 不是一个真正的执行器，参数 this 才是真正的执行器 // 它对执行器进行了包装，每个任务结束后，将结果保存到内部的一个 completionQueue 队列中 // 这也是为什么这个类的名字里面有个 Completion 的原因。 ExecutorCompletionService&lt;T&gt; ecs = new ExecutorCompletionService&lt;T&gt;(this); // For efficiency, especially in executors with limited // parallelism, check to see if previously submitted tasks are // done before submitting more of them. This interleaving // plus the exception mechanics account for messiness of main // loop. try &#123; // 用于保存异常信息，此方法如果没有得到任何有效的结果，那么我们可以抛出最后得到的一个异常 ExecutionException ee = null; final long deadline = timed ? System.nanoTime() + nanos : 0L; Iterator&lt;? extends Callable&lt;T&gt;&gt; it = tasks.iterator(); // 首先先提交一个任务，后面的任务到下面的 for 循环一个个提交 futures.add(ecs.submit(it.next())); --ntasks; // 提交了一个任务，所以任务数量减 1 int active = 1; // 正在执行的任务数(提交的时候 +1，任务结束的时候 -1) for (; ; ) &#123; // ecs 上面说了，其内部有一个 completionQueue 用于保存执行完成的结果 // BlockingQueue的poll方法不阻塞，返回 null 代表队列为空 Future&lt;T&gt; f = ecs.poll(); // 非阻塞 // 为 null，说明刚刚提交的第一个线程还没有执行完成 // 在前面先提交一个任务，加上这里做一次检查，也是为了提高性能 if (f == null) &#123; if (ntasks &gt; 0) &#123; // 再提交一个任务 --ntasks; futures.add(ecs.submit(it.next())); ++active; &#125; else if (active == 0) &#123; // 没有任务了，同时active为0,说明 任务都执行完成了 break; &#125; else if (timed) &#123; f = ecs.poll(nanos, TimeUnit.NANOSECONDS); // 带等待时间的poll方法 if (f == null) &#123; throw new TimeoutException(); // 如果已经超时，抛出 TimeoutException 异常，这整个方法就结束了 &#125; nanos = deadline - System.nanoTime(); &#125; else &#123; f = ecs.take(); // 没有任务了，有一个在运行中，再获取一次结果，阻塞方法，直到任务结束 &#125; &#125; /* * 我感觉上面这一段并不是很好理解，这里简单说下： * 1. 首先，这在一个 for 循环中，我们设想每一个任务都没那么快结束， * 那么，每一次都会进到第一个分支，进行提交任务，直到将所有的任务都提交了 * 2. 任务都提交完成后，如果设置了超时，那么 for 循环其实进入了“一直检测是否超时” 这件事情上 * 3. 如果没有设置超时机制，那么不必要检测超时，那就会阻塞在 ecs.take() 方法上， 等待获取第一个执行结果 * ?. 这里我还没理解 active == 0 这个分支的到底是干嘛的？ */ if (f != null) &#123; // 有任务结束了 --active; try &#123; return f.get(); // 阻塞获取执行结果，如果有异常，都包装成 ExecutionException &#125; catch (ExecutionException eex) &#123; ee = eex; &#125; catch (RuntimeException rex) &#123; ee = new ExecutionException(rex); &#125; &#125; &#125; if (ee == null) &#123; ee = new ExecutionException(); &#125; throw ee; &#125; finally &#123; // 方法退出之前，取消其他的任务 for (int i = 0, size = futures.size(); i &lt; size; i++) &#123; futures.get(i).cancel(true); &#125; &#125;&#125;/** * 将tasks集合中的任务提交到线程池执行，任意一个线程执行完后就可以结束了，不设置超时时间 */public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; try &#123; return doInvokeAny(tasks, false, 0); &#125; catch (TimeoutException cannotHappen) &#123; assert false; return null; &#125;&#125;/** * 将tasks集合中的任务提交到线程池执行，任意一个线程执行完后就可以结束了，需要指定超时时间 */public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return doInvokeAny(tasks, true, unit.toNanos(timeout));&#125; invokeAll123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103 /** * 将tasks集合中的任务提交到线程池执行，全部线程执行完后才可以结束了 * 其实我们自己提交任务到线程池，也是想要线程池执行所有的任务 * 只不过，我们是每次 submit 一个任务，这里以一个集合作为参数提交 */public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; if (tasks == null) &#123; throw new NullPointerException(); &#125; ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; try &#123; for (Callable&lt;T&gt; t : tasks) &#123; // 包装成 FutureTask RunnableFuture&lt;T&gt; f = newTaskFor(t); futures.add(f); // 提交任务 execute(f); &#125; for (int i = 0, size = futures.size(); i &lt; size; i++) &#123; Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) &#123; try &#123; // 这是一个阻塞方法，直到获取到值，或抛出了异常 // 这里有个小细节，其实 get 方法签名上是会抛出 InterruptedException 的 // 可是这里没有进行处理，而是抛给外层去了。此异常发生于还没执行完的任务被取消了 f.get(); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; &#125; &#125; done = true; // 这个方法返回返回 List&lt;Future&gt;，而且是任务都结束了 return futures; &#125; finally &#123; if (!done) &#123; // 异常情况下才会进入 // 方法退出之前，取消其他的任务 for (int i = 0, size = futures.size(); i &lt; size; i++) &#123; futures.get(i).cancel(true); &#125; &#125; &#125;&#125;/** * 带超时的 invokeAll */public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; if (tasks == null) &#123; throw new NullPointerException(); &#125; long nanos = unit.toNanos(timeout); ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; try &#123; for (Callable&lt;T&gt; t : tasks) &#123; futures.add(newTaskFor(t)); &#125; final long deadline = System.nanoTime() + nanos; // 直接计算出超时时刻 final int size = futures.size(); // 提交一个任务，检测一次是否超时 for (int i = 0; i &lt; size; i++) &#123; execute((Runnable) futures.get(i)); nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; return futures; &#125; &#125; for (int i = 0; i &lt; size; i++) &#123; Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) &#123; if (nanos &lt;= 0L) &#123; return futures; &#125; try &#123; // 调用带超时的 get 方法，这里的参数 nanos 是剩余的时间， // 因为上面其实已经用掉了一些时间了 f.get(nanos, TimeUnit.NANOSECONDS); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; catch (TimeoutException toe) &#123; return futures; &#125; nanos = deadline - System.nanoTime(); // 更新剩余时间 &#125; &#125; done = true; return futures; &#125; finally &#123; if (!done) &#123; for (int i = 0, size = futures.size(); i &lt; size; i++) &#123; futures.get(i).cancel(true); &#125; &#125; &#125;&#125; 到这里，我们发现，这个抽象类包装了一些基本的方法，可是像 submit、invokeAny、invokeAll 等方法，它们都没有真正开启线程来执行任务，它们都只是在方法内部调用了 execute 方法，所以最重要的 execute(Runnable runnable) 方法还没出现，需要等具体执行器来实现这个最重要的部分，这里我们要说的就是 ThreadPoolExecutor 类了。 ThreadPoolExecutorThreadPoolExecutor 是 JDK 中的线程池实现，这个类实现了一个线程池需要的各个方法，它实现了任务提交、线程管理、监控等等方法。 构造函数Executors 这个工具类来快速构造一个线程池，对于初学者而言，这种工具类是很有用的，开发者不需要关注太多的细节，只要知道自己需要一个线程池，仅仅提供必需的参数就可以了，其他参数都采用作者提供的默认值。其调用的就是构造函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 构造方法 * * @param corePoolSize 核心线程数 * @param maximumPoolSize 最大线程数，线程池允许创建的最大线程数 * @param keepAliveTime 空闲线程的保活时间，如果某线程的空闲时间超过这个值都没有任务给它做，那么可以被关闭了。 * 注意这个值并不会对所有线程起作用，如果线程池中的线程数少于等于核心线程数 corePoolSize， * 那么这些线程不会因为空闲太长时间而被关闭，当然，也可以通过调用 allowCoreThreadTimeOut(true) * 使核心线程数内的线程也可以被回收 * @param unit 时间单位 * @param workQueue 任务队列，BlockingQueue 接口的某个实现（常使用 ArrayBlockingQueue 和 LinkedBlockingQueue） * @param threadFactory 用于生成线程，一般我们可以用默认的就可以了。 * 通常，我们可以通过它将我们的线程的名字设置得比较可读一些，如 Message-Thread-1， Message-Thread-2 类似这样。 * @param handler 当线程池已经满了，但是又有新的任务提交的时候，该采取什么策略由这个来指定。有 * 几种方式可供选择，像抛出异常、直接拒绝然后返回等，也可以自己实现相应的接口实现自己的逻辑。 */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) &#123; throw new IllegalArgumentException(); &#125; if (workQueue == null || threadFactory == null || handler == null) &#123; throw new NullPointerException(); &#125; this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 关键变量除了构造函数以外，还需要重点关注下几个重要的属性和函数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3; // 29// 线程容量(2^29-1=536 870 911)private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // 000 1111111111111111111111111111/* * RUNNING 定义为 -1， * SHUTDOWN 定义为 0， * 其他的都比 0 大， * 所以等于 0 的时候不能提交任务，大于 0 的话，连正在执行的任务也需要中断 */// runState存储在高3位// 接收新任务，处理队列任务private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 111 00000000000000000000000000000 (-536870912)// 不接受新的任务提交，但是会继续处理等待队列中的任务private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 000 00000000000000000000000000000 (0)// 不接收新任务，也不处理队列任务，并且中断所有处理中的任务private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 001 00000000000000000000000000000 ( 268435456)// 所有任务都被终结，有效线程为0。会触发terminated()方法private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 010 00000000000000000000000000000 (1073741824)// 当terminated()方法执行结束时状态private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // 011 00000000000000000000000000000 (1610612736)// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; // 取高三位，状态&#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; // 取低29位，线程数&#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc;&#125;/* * Bit field accessors that don't require unpacking ctl. * These depend on the bit layout and on workerCount being never negative. */private static boolean runStateLessThan(int c, int s) &#123; return c &lt; s;&#125;private static boolean runStateAtLeast(int c, int s) &#123; return c &gt;= s;&#125;private static boolean isRunning(int c) &#123; return c &lt; SHUTDOWN;&#125;/** * 线程数自增 1 * Attempts to CAS-increment the workerCount field of ctl. */private boolean compareAndIncrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect + 1);&#125;/** * 线程数自减 1 * Attempts to CAS-decrement the workerCount field of ctl. */private boolean compareAndDecrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect - 1);&#125;/** * 只有当某线程被突然终止时才会调用该方法，其他线程数自减是在执行新的task时 * &lt;p&gt; */private void decrementWorkerCount() &#123; do &#123; &#125; while (!compareAndDecrementWorkerCount(ctl.get()));&#125; 看了这几种状态的介绍，读者大体也可以猜到十之八九的状态转换了，各个状态的转换过程有以下几种： 123456789RUNNING -&gt; SHUTDOWN：当调用了 shutdown() 后，会发生这个状态转换，这也是最重要的(RUNNING or SHUTDOWN) -&gt; STOP：当调用 shutdownNow() 后，会发生这个状态转换，这下要清楚 shutDown() 和 shutDownNow() 的区别了SHUTDOWN -&gt; TIDYING：当任务队列和线程池都清空后，会由 SHUTDOWN 转换为 TIDYINGSTOP -&gt; TIDYING：当任务队列清空后，发生这个转换TIDYING -&gt; TERMINATED：这个前面说了，当 terminated() 方法结束后 上面的几个记住核心的就可以了，尤其第一个和第二个。 另外，我们还要看看一个内部类 Worker，因为 Doug Lea 把线程池中的线程包装成了一个个 Worker，翻译成工人，就是线程池中做任务的线程。所以到这里，我们知道任务是 Runnable（内部叫 task 或 command），线程是 Worker。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/*** 继承了AbstractQueuedSynchronizer以简化获取和释放围绕每个任务执行的锁。* 这可以防止中断旨在唤醒等待任务的工作线程，而不是中断正在运行的任务。*/private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; private static final long serialVersionUID = 6138294804551838833L; /** * 由ThreadFactory创建的真实执行任务的线程 */ final Thread thread; /** * 前面说了，这里的 Runnable 是任务。 * 为什么叫 firstTask？因为在创建线程的时候，如果同时指定了这个线程起来以后需要执行的第一个任务， * 那么第一个任务就是存放在这里的(线程可不止执行这一个任务) * 当然了，也可以为 null，这样线程起来了，自己到任务队列（BlockingQueue）中取任务（getTask 方法） */ Runnable firstTask; /** * 用于存放此线程完全的任务数，注意了，这里用了 volatile，保证可见性 */ volatile long completedTasks; /** * Worker 只有这一个构造方法，传入 firstTask，也可以传 null */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 调用 ThreadFactory 来创建一个新的线程 this.thread = getThreadFactory().newThread(this); &#125; /** * 这里调用了外部类的 runWorker 方法 */ public void run() &#123; runWorker(this); &#125; ...// 其他几个方法没什么好看的，就是用 AQS 操作，来获取这个线程的执行权，用了独占锁&#125; excute()有了上面的这些基础后，我们终于可以看看 ThreadPoolExecutor 的 execute 方法了，前面源码分析的时候也说了，各种方法都最终依赖于 execute 方法. 首先分析下execute主要工作流程： （1）任务submit后先通过newTaskFor()封装成可返回结果的FutureTask; （2）调用execute方法执行； （3）execute方法在当前线程数（WC）小于coreSize时，直接创建新线程处理； （4）如果创建新线程失败，尝试加入任务队列，若此时线程池已经处于非Running状态，则不做处理； （5）成功加入任务队列后需要再次确认线程池状态（有可能在加入队列操作的过程中，线程池被shutdown了），如果此时线程池非Running,则移除该任务，执行拒绝策略；如果状态正常，则判断WC==0，如果等于0说明线程池中没有线程了，则创建一个新线程添加到pool中； （6）如果加入队列失败或者当前状态非Running, 则尝试创建新线程来处理该任务，如果失败，则执行拒绝策略； 具体流程如下图： 本来想用一张图表示整个流程，结果发现图还没有看源代码清晰，干脆放弃了，直接看代码吧。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void execute(Runnable command) &#123; if (command == null) &#123; throw new NullPointerException(); &#125; /* * 三步走： * * 1. 当前线程数小于corePoolSize，添加一个新的worker,并把commond作为其第一个任务。 * 调用addWorker()方法会自动检查runState和workerCount，避免因为状态问题报错 * * 2. 任务成功加入队列后，仍然需要再次确认是否增加新的工作线程（有可能在上次检测运行线程数之后某些线程挂了）， * 或者在进入这个方法时，线程池shut down了。 * So we recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. 如果无法添加到队列，则尝试创建新线程。如果失败，则表示线程池shutdown了或者需要执行拒绝策略了。 * * 由此可见：在线程数超过corePoolSize后，只有队列满了才会再次创建新线程 */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; // 添加任务成功，那么就结束了。提交任务嘛，线程池已经接受了这个任务，这个方法也就可以返回了 // 至于执行的结果，到时候会包装到 FutureTask 中。 // 返回 false 代表线程池不允许提交任务 if (addWorker(command, true)) &#123; return; &#125; c = ctl.get(); &#125; // 到这里说明，要么当前线程数大于等于核心线程数，要么刚刚 addWorker 失败了 // 如果线程池处于 RUNNING 状态，把这个任务添加到任务队列 workQueue 中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; /* 如果任务进入了 workQueue，我们是否需要开启新的线程 * 因为线程数在 [0, corePoolSize) 是无条件开启新的线程 * 如果线程数已经大于等于 corePoolSize，那么将任务添加到队列中，然后进到这里 */ int recheck = ctl.get(); if (!isRunning(recheck) &amp;&amp; remove(command)) &#123; // 如果线程池已不处于RUNNING状态，那么移除已经入队的这个任务 reject(command); // 执行拒绝策略 &#125; else if (workerCountOf(recheck) == 0) &#123; // 如果线程池还是 RUNNING 的，并且线程数为 0，那么开启新的线程 // 这块代码的真正意图是：担心任务提交到队列中了，但是线程都关闭了 addWorker(null, false); &#125; &#125; else if (!addWorker(command, false)) &#123; // 线程池非Running或者队列满了，尝试创建新线程 // 创建新线程失败，说明当前线程数已经达到 maximumPoolSize，执行拒绝策略 reject(command); &#125;&#125; addWorker()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * 简单分析： * 还是状态控制的问题，当线程池处于 SHUTDOWN 的时候，不允许提交任务，但是已有的任务继续执行 * 当状态大于 SHUTDOWN 时，不允许提交任务，且中断正在执行的任务 * 多说一句： * 如果线程池处于 SHUTDOWN，但是firstTask为null，且 workQueue 非空，那么是允许创建 worker 的 * * @param firstTask 准备提交给这个线程执行的第一个任务，可以为null. * @param core true 代表使用核心线程数 corePoolSize 作为创建线程的界线，也就说创建这个线程的时候， * 如果线程池中的线程总数已经达到 corePoolSize，那么不能响应这次创建线程的请求 * 如果是 false，代表使用最大线程数 maximumPoolSize 作为界线 */private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (; ; ) &#123; int c = ctl.get(); int rs = runStateOf(c); // 获取当前状态 // 如果线程池已关闭，并满足以下条件之一，那么不创建新的 worker： // 1. 线程池状态大于SHUTDOWN，其实也就是 STOP, TIDYING, 或 TERMINATED // 2. firstTask不为空 // 3. 任务队列为空 if (rs &gt;= SHUTDOWN &amp;&amp; !(rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; !workQueue.isEmpty())) &#123; return false; &#125; for (; ; ) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) &#123; // 超容量了或者超过当前限制了，不允许创建 return false; &#125; // 如果成功，那么就是所有创建线程前的条件校验都满足了，准备创建线程执行任务了 // 这里失败的话，说明有其他线程也在尝试往线程池中创建线程 if (compareAndIncrementWorkerCount(c)) &#123; break retry; // 退出循环，准备创建线程执行任务 &#125; c = ctl.get(); // 由于有并发，重新再读取一下 ctl // 正常如果是 CAS 失败的话，进到下一个里层的for循环就可以了 // 可是如果是因为其他线程的操作，导致线程池的状态发生了变更，如有其他线程关闭了这个线程池 // 那么需要回到外层的for循环 if (runStateOf(c) != rs) &#123; continue retry; &#125; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; /* * 到这里，我们认为在当前这个时刻，可以开始创建线程来执行任务了， * 因为该校验的都校验了，至于以后会发生什么，那是以后的事，至少当前是满足条件的 */ boolean workerStarted = false; // worker 是否已经启动 boolean workerAdded = false; // 是否已将这个 worker 添加到 workers 这个 HashSet 中 Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; // 这个是整个类的全局锁，持有这个锁才能让下面的操作“顺理成章”， // 因为关闭一个线程池需要这个锁，至少我持有锁的期间，线程池不会被关闭 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // 小于 SHUTTDOWN 那就是 RUNNING，这个自不必说，是最正常的情况 // 如果等于 SHUTDOWN，前面说了，不接受新的任务，但是会继续执行等待队列中的任务 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // 检测线程是否已经是start状态 &#123; // 新添加的worker里面的 thread 可不能是已经启动的 throw new IllegalThreadStateException(); &#125; workers.add(w); // 加到 workers 这个 HashSet 中 int s = workers.size(); // largestPoolSize 用于记录 workers 中的个数的历史最大值 // 因为 workers 是不断增加减少的，通过这个值可以知道线程池的大小曾经达到的最大值 if (s &gt; largestPoolSize) &#123; largestPoolSize = s; &#125; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 添加成功的话，启动这个线程 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (!workerStarted) &#123; // 如果线程没有启动，需要做一些清理工作，如前面 workCount 加了 1，将其减掉 addWorkerFailed(w); &#125; &#125; // 返回线程是否启动成功 return workerStarted;&#125; addWorkFailed()12345678910111213141516171819/** * 线程创建失败回滚 * workers 中删除掉相应的 worker * workCount 减 1 * 终止检查，防止这个线程的存在阻碍了线程池的terminate */private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) &#123; workers.remove(w); &#125; decrementWorkerCount(); tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; runWorker()回过头来，继续往下走。我们知道，worker 中的线程 start 后，其 run 方法会调用 runWorker 方法： 1234// Worker 类的 run() 方法public void run() &#123; runWorker(this);&#125; 继续往下看 runWorker 方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 实际执行task, 循环从队列中取任务执行 * * @param w the worker */final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 循环调用 getTask 获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // 如果线程池状态大于等于 STOP，那么意味着该线程也要中断 // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) &#123; wt.interrupt(); &#125; try &#123; // 这是一个钩子方法，留给需要的子类实现 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 到这里终于可以执行任务了 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; // 这里不允许抛出 Throwable，所以转换为 Erro thrown = x; throw new Error(x); &#125; finally &#123; // 也是一个钩子方法，将 task 和异常作为参数，留给需要的子类实现 afterExecute(task, thrown); &#125; &#125; finally &#123; // 置空 task，准备 getTask 获取下一个任务 task = null; // 累加该worker完成的任务数 w.completedTasks++; // 释放掉 worker 的独占锁 w.unlock(); &#125; &#125; completedAbruptly = false; // 执行到这儿说明是getTask()为空，而不是报异常了 &#125; finally &#123; // 如果到这里，需要执行线程关闭： // 1. 说明 getTask 返回 null，也就是说，这个 worker 的使命结束了，执行关闭 // 2. 任务执行过程中发生了异常 // 第一种情况，已经在代码处理了将 workCount 减 1，这个在 getTask 方法分析中会说 // 第二种情况，workCount 没有进行处理，所以需要在 processWorkerExit 中处理 processWorkerExit(w, completedAbruptly); &#125;&#125; processWorkerExit()12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 线程终止后: * 1. 如果是异常退出, 则需要减掉当前workercCount * 2. 更新线程池完成任务数 * 3. 从workers中移除终止的线程； * 4. 终止检测 * 5. 如果线程池当前处于RUNNING/SHUTDOWN状态： * a) 允许回收核心线程时，至少要保证有一个worker线程； * b) 不允许回收核心线程时，当前线程小于corePoolSize，则创建新的线程； * c）如果worker线程是由于异常退出，则直接创建一个新的worker线程 * * @param w the worker * @param completedAbruptly true woker执行异常 */private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted &#123; decrementWorkerCount(); &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 终止检查，防止这个线程的存在阻碍了线程池的terminate tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; // RUNNING/SHUTDOWN if (!completedAbruptly) &#123; // 说明当前任务队列中没有任务 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; !workQueue.isEmpty()) &#123; // 允许回收核心线程 min = 1; &#125; if (workerCountOf(c) &gt;= min) &#123; // 当前线程数大于1 或者 corePoolSize, 暂时不创建新的线程 return; // replacement not needed &#125; &#125; addWorker(null, false); // 添加新的备用线程 &#125;&#125; getTask()getTask() 是怎么获取任务的，这个方法写得真的很好，每一行都很简单，组合起来却所有的情况都想好了： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 此方法有三种可能： * 1. 阻塞直到获取到任务返回。我们知道，默认 corePoolSize 之内的线程是不会被回收的，它们会一直等待任务 * 2. 超时退出。keepAliveTime 起作用的时候，也就是如果这么多时间内都没有任务，那么应该执行关闭 * 3. 如果发生了以下条件，此方法必须返回 null: * - 池中有大于 maximumPoolSize 个 workers 存在(通过调用 setMaximumPoolSize 进行设置) * - 线程池处于 SHUTDOWN，而且 workQueue 是空的，前面说了，这种不再接受新的任务 * - 线程池处于 STOP，不仅不接受新的线程，连 workQueue 中的线程也不再执行 */private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (; ; ) &#123; int c = ctl.get(); int rs = runStateOf(c); // 两种可能 // 1. rs == SHUTDOWN &amp;&amp; workQueue.isEmpty() // 2. rs &gt;= STOP if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); // 减少工作线程数, processWorkerExit()方法中会将该线程移除 return null; &#125; int wc = workerCountOf(c); // 允许核心线程数内的线程回收，或当前线程数超过了核心线程数，那么有可能发生超时关闭 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 当前线程数超过maximumPoolSize // 允许回收核心线程或者当前线程超过corePoolSize &amp;&amp; 超时 // wc &gt; 1 或者 队列为空 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) &#123; // 减掉线程数 return null; // 获取任务的worker取不到任务就会退出 &#125; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : // 等待一定时间，如果仍然获取不到说明线程数过多，任务不够 workQueue.take(); // 阻塞获取 if (r != null) &#123; return r; &#125; timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果此 worker 发生了中断，采取的方案是重试 // 解释下为什么会发生中断，这个读者要去看 setMaximumPoolSize 方法， // 如果开发者将 maximumPoolSize 调小了，导致其小于当前的 workers 数量， // 那么意味着超出的部分线程要被关闭。重新进入 for 循环，自然会有部分线程会返回 null timedOut = false; &#125; &#125;&#125; tryTerminate()1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 把线程池状态设置为TERMINATED，在以下条件之一： * 1. SHUTDOWN 并且 pool线程和队列都为空； * 2. STOP 并且 pool线程为空； * &lt;p&gt; * 如果线程不为0时想要优雅终止，则中断空闲的worker线程以保证shutdown信号得到传播。 * * This method must be called following any action that might make * termination possible -- reducing worker count or removing tasks * from the queue during shutdown. The method is non-private to * allow access from ScheduledThreadPoolExecutor. */final void tryTerminate() &#123; for (; ; ) &#123; int c = ctl.get(); // 状态为RUNNING、SHUTDOWN、STOP 或者 (SHUTDOWN &amp;&amp; 队列不为空) 不允许 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; !workQueue.isEmpty())) &#123; return; &#125; if (workerCountOf(c) != 0) &#123; // 终止一个空闲线程 interruptIdleWorkers(ONLY_ONE); return; &#125; // 当前线程数为0 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; // 设置状态为TIDYING try &#123; terminated(); // 触发终止后方法 &#125; finally &#123; ctl.set(ctlOf(TERMINATED, 0)); // 最终设置为TERMINATED状态 termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125; 拒绝策略ThreadPoolExecutor 中的拒绝策略。 12345678910111213141516171819/** * 此处的 handler 我们需要在构造线程池的时候就传入这个参数，它是 RejectedExecutionHandler 的实例。 * RejectedExecutionHandler 在 ThreadPoolExecutor 中有四个已经定义好的实现类可供我们直接使用， * 当然，我们也可以实现自己的策略，不过一般也没有必要。简要介绍下四中默认的拒绝策略： * &lt;p&gt; * 1. CallerRunsPolicy： 只要线程池没有被关闭，那么由提交任务的线程自己来执行这个任务 * &lt;p&gt; * 2. AbortPolicy：不管怎样，直接抛出 RejectedExecutionException 异常， 这个是默认的策略， * 如果我们构造线程池的时候不传相应的 handler 的话，那就会指定使用这个 * &lt;p&gt; * 3. DiscardPolicy：不做任何处理，直接忽略掉这个任务 * &lt;p&gt; * 4. DiscardOldestPolicy： 这个相对霸道一点，如果线程池没有被关闭的话， 把队列队头的任务(也就是等待了最长时间的)直接扔掉， * 然后提交这个任务到等待队列中 */ final void reject(Runnable command) &#123; // 执行拒绝策略 handler.rejectedExecution(command, this); &#125; Executors Executors它仅仅是工具类，它的所有方法都是 static 的。 FixedThreadPoole生成一个固定大小的线程池： 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 最大线程数设置为与核心线程数相等，此时 keepAliveTime 设置为 0（因为这里它是没用的，即使不为 0 也不会执行 corePoolSize 内的线程），任务队列采用 LinkedBlockingQueue，无界队列。 过程分析：刚开始，每提交一个任务都创建一个 worker，当 worker 的数量达到 nThreads 后，不再创建新的线程，而是把任务提交到 LinkedBlockingQueue 中，而且之后线程数始终为 nThreads。 SingleThreadExecutor生成只有一个线程的固定线程池，这个更简单，和上面的一样，只要设置线程数为 1 就可以了： 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; newCachedThreadPool生成一个需要的时候就创建新的线程，同时可以复用之前创建的线程（如果这个线程当前没有任务）的线程池： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 过程分析：鉴于 corePoolSize 是 0，那么提交任务的时候，直接将任务提交到队列中，由于采用了 SynchronousQueue，所以如果是第一个任务提交的时候，offer 方法肯定会返回 false，因为此时没有任何 worker 对这个任务进行接收，那么将进入到最后一个分支来创建第一个 worker。之后再提交任务的话，取决于是否有空闲下来的线程对任务进行接收，如果有，会进入到第二个 if 语句块中，否则就是和第一个任务一样，进到最后的 else if 分支。 这种线程池对于任务可以比较快速地完成的情况有比较好的性能。如果线程空闲了 60 秒都没有任务，那么将关闭此线程并从线程池中移除。所以如果线程池空闲了很长时间也不会有问题，因为随着所有的线程都会被关闭，整个线程池不会占用任何的系统资源。 SynchronousQueue 是一个比较特殊的 BlockingQueue，其本身不储存任何元素，它有一个虚拟队列（或虚拟栈），不管读操作还是写操作，如果当前队列中存储的是与当前操作相同模式的线程，那么当前操作也进入队列中等待；如果是相反模式，则配对成功，从当前队列中取队头节点。具体的信息，可以看我的另一篇关于 BlockingQueue 的文章。 代码带注释完整代码： https://github.com/austin-brant/thread-pool-source-code]]></content>
      <categories>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>Java</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-Boot + Kafka实现生产+批量消费]]></title>
    <url>%2F2019%2F07%2F16%2FSpring-Boot-Kafka%E5%AE%9E%E7%8E%B0%E7%94%9F%E4%BA%A7-%E6%89%B9%E9%87%8F%E6%B6%88%E8%B4%B9%2F</url>
    <content type="text"><![CDATA[本文是Springboot + Kafka实现消息写入和批量消费，属于一个学习demo，下面直接上代码。 POM依赖1234567891011121314151617181920212223242526272829303132333435&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;version&gt;2.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#============== kafka ===================# 指定kafka 代理地址，可以多个spring.kafka.bootstrap-servers=10.101.38.213:8092#指定template默认topic idspring.kafka.template.default-topic=topic-test#=============== provider =======================## 重试次数spring.kafka.producer.retries=3# 批量发送消息数量Bytesspring.kafka.producer.batch-size=16384# 32M批处理缓冲区spring.kafka.producer.buffer-memory=33554432spring.kafka.producer.properties.linger-ms=1# 指定消息key和消息体的编解码方式spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer#=============== consumer =======================# 指定默认消费者group idspring.kafka.consumer.group-id=etl# 最早未被消费的offset, 若设置为earliest，那么会从头开始读partitionspring.kafka.consumer.auto-offset-reset=earliest# 批量一次最大拉取数据量spring.kafka.consumer.max-poll-records=5# 如果没有足够的数据立即满足“fetch.min.bytes”给出的要求，服务器在回答获取请求之前将阻塞的最长时间（以毫秒为单位）spring.kafka.consumer.fetch-max-wait=10000# 自动提交spring.kafka.consumer.enable-auto-commit=falsespring.kafka.consumer.auto-commit-interval=10000# 连接超时时间, 自定义spring.kafka.consumer.session-timeout=15000# 指定消息key和消息体的编解码方式spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer#=============== listener =======================# 指定listener 容器中的线程数，用于提高并发量spring.kafka.listener.concurrency=1# 轮询消费者时使用的超时（以毫秒为单位）spring.kafka.listener.poll-timeout=50000# 是否开启批量消费，true表示批量消费spring.kafka.listener.batch-listener=truetopic.name=springDemo Kafka配置 如果不需要批量消费，只需KafkaTemplate进行produce， 则不需要该显式配置类，spring-boot的自动配置会根据配置文件帮我们创建好KafkaTemplate对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136package com.austin.brant.kafka.demo.config;import java.util.HashMap;import java.util.Map;import org.apache.kafka.clients.consumer.ConsumerConfig;import org.apache.kafka.clients.producer.ProducerConfig;import org.apache.kafka.common.serialization.StringDeserializer;import org.apache.kafka.common.serialization.StringSerializer;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.kafka.annotation.EnableKafka;import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;import org.springframework.kafka.config.KafkaListenerContainerFactory;import org.springframework.kafka.core.DefaultKafkaConsumerFactory;import org.springframework.kafka.core.DefaultKafkaProducerFactory;import org.springframework.kafka.core.KafkaTemplate;import org.springframework.kafka.core.ProducerFactory;import org.springframework.kafka.listener.ContainerProperties;/** * @author austin-brant * @since 2019/7/15 21:45 */@Configuration@EnableKafkapublic class KafkaConfig &#123; @Value("$&#123;spring.kafka.bootstrap-servers&#125;") private String bootstrapServers; @Value("$&#123;spring.kafka.producer.retries&#125;") private String producerRetries; // 生产者重试次数 @Value("$&#123;spring.kafka.producer.batch-size&#125;") private String producerBatchSize; @Value("$&#123;spring.kafka.producer.properties.linger-ms&#125;") private String producerLingerMs; @Value("$&#123;spring.kafka.producer.buffer-memory&#125;") private String producerBufferMemory; @Value("$&#123;spring.kafka.consumer.enable-auto-commit&#125;") private Boolean autoCommit; @Value("$&#123;spring.kafka.consumer.auto-commit-interval&#125;") private Integer autoCommitInterval; @Value("$&#123;spring.kafka.consumer.group-id&#125;") private String groupId; @Value("$&#123;spring.kafka.consumer.max-poll-records&#125;") private Integer maxPollRecords; @Value("$&#123;spring.kafka.consumer.fetch-max-wait&#125;") private Integer maxPollIntervals; @Value("$&#123;spring.kafka.consumer.auto-offset-reset&#125;") private String autoOffsetReset; @Value("$&#123;spring.kafka.listener.concurrency&#125;") private Integer concurrency; @Value("$&#123;spring.kafka.listener.poll-timeout&#125;") private Long pollTimeout; @Value("$&#123;spring.kafka.consumer.session-timeout&#125;") private String sessionTimeout; @Value("$&#123;spring.kafka.listener.batch-listener&#125;") private Boolean batchListener; /** * ProducerFactory */ @Bean public ProducerFactory&lt;String, String&gt; producerFactory() &#123; Map&lt;String, Object&gt; configs = new HashMap&lt;String, Object&gt;(); //参数 configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); configs.put(ProducerConfig.RETRIES_CONFIG, producerRetries); configs.put(ProducerConfig.BATCH_SIZE_CONFIG, producerBatchSize); configs.put(ProducerConfig.LINGER_MS_CONFIG, producerLingerMs); configs.put(ProducerConfig.BUFFER_MEMORY_CONFIG, producerBufferMemory); configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); return new DefaultKafkaProducerFactory&lt;String, String&gt;(configs); &#125; /** * KafkaTemplate */ @Bean public KafkaTemplate&lt;String, String&gt; kafkaTemplate() &#123; return new KafkaTemplate&lt;String, String&gt;(producerFactory(), true); &#125; /** * 添加KafkaListenerContainerFactory，用于批量消费消息 */ @Bean public KafkaListenerContainerFactory&lt;?&gt; batchFactory() &#123; ConcurrentKafkaListenerContainerFactory&lt;Object, Object&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(new DefaultKafkaConsumerFactory&lt;Object, Object&gt;(consumerConfigs())); factory.setBatchListener(batchListener); // 开启批量监听 factory.setConcurrency(concurrency); // 并发消费线程 factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE); factory.getContainerProperties().setPollTimeout(pollTimeout); return factory; &#125; @Bean public Map&lt;String, Object&gt; consumerConfigs() &#123; Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, maxPollRecords); // 批量消费的数量 props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, maxPollIntervals); //每一批读取间隔时间 props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, autoOffsetReset); // 最早未被消费的offset props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, autoCommit); // 是否自动提交 props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, autoCommitInterval); // 自动提交间隔 props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, sessionTimeout); // props.put(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 180000); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); return props; &#125;&#125; 生产者1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.austin.brant.kafka.demo.provider;import java.util.Date;import java.util.List;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.kafka.core.KafkaTemplate;import org.springframework.kafka.support.SendResult;import org.springframework.stereotype.Component;import org.springframework.util.concurrent.ListenableFuture;import org.springframework.util.concurrent.ListenableFutureCallback;import com.austin.brant.kafka.demo.model.Message;import lombok.extern.slf4j.Slf4j;/** * 生产者 * * @author austin-brant * @since 2019/7/15 19:39 */@Component@Slf4jpublic class KafkaProducer &#123; @Autowired private KafkaTemplate&lt;String, String&gt; kafkaTemplate; public void send(String topic, String message) &#123; ListenableFuture&lt;SendResult&lt;String, String&gt;&gt; future = kafkaTemplate.send(topic, Message.builder() .id(System.currentTimeMillis()) .msg(message) .sendTime(new Date()).build().toString()); future.addCallback(new ListenableFutureCallback&lt;SendResult&lt;String, String&gt;&gt;() &#123; @Override public void onFailure(Throwable throwable) &#123; log.error("send message [&#123;&#125;] to topic [&#123;&#125;] failed, ", message, topic); &#125; @Override public void onSuccess(SendResult&lt;String, String&gt; stringStringSendResult) &#123; log.info("send message [&#123;&#125;] to topic [&#123;&#125;] success, ", message, topic); &#125; &#125;); log.info("send message end"); &#125; public void batchSend(String topic, List&lt;String&gt; message) &#123; message.forEach(it -&gt; kafkaTemplate.send(topic, it)); &#125;&#125; 消费者12345678910111213141516171819202122232425262728293031323334353637383940414243package com.austin.brant.kafka.demo.consumer;import java.util.List;import org.apache.kafka.clients.consumer.ConsumerRecord;import org.springframework.kafka.annotation.KafkaListener;import org.springframework.kafka.support.Acknowledgment;import org.springframework.stereotype.Component;import lombok.extern.slf4j.Slf4j;/** * 消费者 * * @author austin-brant * @since 2019/7/15 19:58 */@Slf4j@Componentpublic class KafkaConsumer &#123; // @KafkaListener(topics = "$&#123;topic.name&#125;") // public void listen(ConsumerRecord&lt;String, String&gt; record) &#123; // consumer(record); // &#125; @KafkaListener(topics = &#123;"$&#123;topic.name&#125;"&#125;, containerFactory = "batchFactory", id = "consumer") public void listen(List&lt;ConsumerRecord&lt;String, String&gt;&gt; records, Acknowledgment ack) &#123; log.info("batch listen size &#123;&#125;.", records.size()); try &#123; records.forEach(it -&gt; consumer(it)); &#125; finally &#123; ack.acknowledge(); //手动提交偏移量 &#125; &#125; /** * 单条消费 */ public void consumer(ConsumerRecord&lt;String, String&gt; record) &#123; log.info("主题:&#123;&#125;, 内容: &#123;&#125;", record.topic(), record.value()); &#125;&#125; 完整代码：https://github.com/austin-brant/kafka-spring-boot-demo]]></content>
      <categories>
        <category>Spring-Boot</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java常用设计模式]]></title>
    <url>%2F2019%2F07%2F15%2FJava%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Java常用设计模式设计模式是对大家实际工作中写的各种代码进行高层次抽象的总结，其中最出名的当属 Gang of Four (GoF) 的分类了，他们将设计模式分类为 23 种经典的模式，根据用途我们又可以分为三大类，分别为: 创建型模式 结构型模式 行为型模式 六大原则有6大重要的设计原则在开篇和大家分享下，这些原则将贯通全文： 单一职责原则每个类都应该只有一个单一的功能，并且该功能应该由这个类完全封装起来。 开发-封闭原则对修改关闭，对扩展开放。对修改关闭是说，我们辛辛苦苦加班写出来的代码，该实现的功能和该修复的 bug 都完成了，别人可不能说改就改；对扩展开放就比较好理解了，也就是说在我们写好的代码基础上，很容易实现扩展。它是面向对象设计的核心所在。 依赖倒转原则抽象不应该依赖细节，细节应该依赖于抽象，说白了就是要针对接口编程，不要面向实现编程。a)高层模块不应依赖低层模块。两个都应该依赖抽象；b)抽象不应该依赖细节。细节应该依赖抽象。 里氏代换原则白话翻译：一个软件实体如果使用的是一个父类的话，那么一定适用于其子类，而且它察觉不出父类对象和子类对象的区别。也就是说：在软件里把父类都用子类替换，程序行为不会变化。 总结成一句话就是：子类型必须能够替换它们的父类型。 接口隔离原则类间的依赖关系应该建立在最小的接口上。通俗来讲：建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。也就是说，我们要为各个类建立专用的接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。 迪米特法则也叫最少知识原则。如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。其根本思想就是强调类之间的松耦合。 创建型模式创建型模式的作用就是创建对象，说到创建一个对象，最熟悉的就是 new 一个对象，然后 set 相关属性。但是，在很多场景下，我们需要给客户端提供更加友好的创建对象的方式，尤其是那种我们定义了类，但是需要提供给其他开发者用的时候。 简单工厂模式和名字一样简单，非常简单，直接上代码吧： 123456789101112131415public class FoodFactory &#123; public static Food makeFood(String name) &#123; if (name.equals("noodle")) &#123; Food noodle = new LanZhouNoodle(); noodle.addSpicy("more"); return noodle; &#125; else if (name.equals("chicken")) &#123; Food chicken = new HuangMenChicken(); chicken.addCondiment("potato"); return chicken; &#125; else &#123; return null; &#125; &#125;&#125; 其中，LanZhouNoodle 和 HuangMenChicken 都继承自 Food。 简单地说，简单工厂模式通常就是这样，一个工厂类 XxxFactory，里面有一个静态方法，根据我们不同的参数，返回不同的派生自同一个父类（或实现同一接口）的实例对象。 我们强调职责单一原则，一个类只提供一种功能，FoodFactory 的功能就是只要负责生产各种 Food。 工厂模式简单工厂模式很简单，如果它能满足我们的需要，我觉得就不要折腾了。之所以需要引入工厂模式，是因为我们往往需要使用两个或两个以上的工厂。 1234567891011121314151617181920212223242526272829public interface FoodFactory &#123; Food makeFood(String name);&#125;public class ChineseFoodFactory implements FoodFactory &#123; @Override public Food makeFood(String name) &#123; if (name.equals("A")) &#123; return new ChineseFoodA(); &#125; else if (name.equals("B")) &#123; return new ChineseFoodB(); &#125; else &#123; return null; &#125; &#125;&#125;public class AmericanFoodFactory implements FoodFactory &#123; @Override public Food makeFood(String name) &#123; if (name.equals("A")) &#123; return new AmericanFoodA(); &#125; else if (name.equals("B")) &#123; return new AmericanFoodB(); &#125; else &#123; return null; &#125; &#125;&#125; 其中，ChineseFoodA、ChineseFoodB、AmericanFoodA、AmericanFoodB 都派生自 Food。 客户端调用： 12345678public class APP &#123; public static void main(String[] args) &#123; // 先选择一个具体的工厂 FoodFactory factory = new ChineseFoodFactory(); // 由第一步的工厂产生具体的对象，不同的工厂造出不一样的对象 Food food = factory.makeFood("A"); &#125;&#125; 虽然都是调用 makeFood(“A”) 制作 A 类食物，但是，不同的工厂生产出来的完全不一样。 第一步，我们需要选取合适的工厂，然后第二步基本上和简单工厂一样。核心在于，我们需要在第一步选好我们需要的工厂。比如，我们有 LogFactory 接口，实现类有 FileLogFactory 和 KafkaLogFactory，分别对应将日志写入文件和写入 Kafka 中，显然，我们客户端第一步就需要决定到底要实例化 FileLogFactory 还是 KafkaLogFactory，这将决定之后的所有的操作。 虽然简单，不过我也把所有的构件都画到一张图上，这样读者看着比较清晰： 抽象工厂模式当涉及到产品族的时候，就需要引入抽象工厂模式了。 一个经典的例子是造一台电脑。我们先不引入抽象工厂模式，看看怎么实现。 因为电脑是由许多的构件组成的，我们将 CPU 和主板进行抽象，然后 CPU 由 CPUFactory 生产，主板由 MainBoardFactory 生产，然后，我们再将 CPU 和主板搭配起来组合在一起，如下图： 这个时候的客户端调用是这样的： 12345678910// 得到 Intel 的 CPUCPUFactory cpuFactory = new IntelCPUFactory();CPU cpu = intelCPUFactory.makeCPU();// 得到 AMD 的主板MainBoardFactory mainBoardFactory = new AmdMainBoardFactory();MainBoard mainBoard = mainBoardFactory.make();// 组装 CPU 和主板Computer computer = new Computer(cpu, mainBoard); 单独看 CPU 工厂和主板工厂，它们分别是前面我们说的工厂模式。这种方式也容易扩展，因为要给电脑加硬盘的话，只需要加一个 HardDiskFactory 和相应的实现即可，不需要修改现有的工厂。 但是，这种方式有一个问题，那就是如果 Intel 家产的 CPU 和 AMD 产的主板不能兼容使用，那么这代码就容易出错，因为客户端并不知道它们不兼容，也就会错误地出现随意组合。 下面就是我们要说的产品族的概念，它代表了组成某个产品的一系列附件的集合： 当涉及到这种产品族的问题的时候，就需要抽象工厂模式来支持了。我们不再定义 CPU 工厂、主板工厂、硬盘工厂、显示屏工厂等等，我们直接定义电脑工厂，每个电脑工厂负责生产所有的设备，这样能保证肯定不存在兼容问题。 这个时候，对于客户端来说，不再需要单独挑选 CPU厂商、主板厂商、硬盘厂商等，直接选择一家品牌工厂，品牌工厂会负责生产所有的东西，而且能保证肯定是兼容可用的。 12345678910111213public static void main(String[] args) &#123; // 第一步就要选定一个“大厂” ComputerFactory cf = new AmdFactory(); // 从这个大厂造 CPU CPU cpu = cf.makeCPU(); // 从这个大厂造主板 MainBoard board = cf.makeMainBoard(); // 从这个大厂造硬盘 HardDisk hardDisk = cf.makeHardDisk(); // 将同一个厂子出来的 CPU、主板、硬盘组装在一起 Computer result = new Computer(cpu, board, hardDisk);&#125; 当然，抽象工厂的问题也是显而易见的，比如我们要加个显示器，就需要修改所有的工厂，给所有的工厂都加上制造显示器的方法。这有点违反了对修改关闭，对扩展开放这个设计原则。 单例模式单例模式用得最多，错得最多。 饿汉模式最简单： 1234567891011121314151617public class Singleton &#123; // 首先，将 new Singleton() 堵死 private Singleton() &#123;&#125;; // 创建私有静态实例，意味着这个类第一次使用的时候就会进行创建 private static Singleton instance = new Singleton(); public static Singleton getInstance() &#123; return instance; &#125; // 瞎写一个静态方法。这里想说的是，如果我们只是要调用 Singleton.getDate(...)， // 本来是不想要生成 Singleton 实例的，不过没办法，已经生成了 public static Date getDate(String mode) &#123; return new Date(); &#125;&#125; 很多人都能说出饿汉模式的缺点，可是我觉得生产过程中，很少碰到这种情况：你定义了一个单例的类，不需要其实例，可是你却把一个或几个你会用到的静态方法塞到这个类中。 饱汉模式最容易出错： 1234567891011121314151617181920public class Singleton &#123; // 首先，也是先堵死 new Singleton() 这条路 private Singleton() &#123;&#125; // 和饿汉模式相比，这边不需要先实例化出来，注意这里的 volatile，它是必须的 private static volatile Singleton instance = null; public static Singleton getInstance() &#123; if (instance == null) &#123; // 加锁 synchronized (Singleton.class) &#123; // 这一次判断也是必须的，不然会有并发问题 if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 双重检查，指的是两次检查 instance 是否为 null。volatile 在这里是需要的，希望能引起读者的关注。很多人不知道怎么写，直接就在 getInstance() 方法签名上加上 synchronized，这就不多说了，性能太差。 嵌套类最经典，以后大家就用它吧： 1234567891011public class Singleton3 &#123; private Singleton3() &#123;&#125; // 主要是使用了 嵌套类可以访问外部类的静态属性和静态方法 的特性 private static class Holder &#123; private static Singleton3 instance = new Singleton3(); &#125; public static Singleton3 getInstance() &#123; return Holder.instance; &#125;&#125; 注意，很多人都会把这个嵌套类说成是静态内部类，严格地说，内部类和嵌套类是不一样的，它们能访问的外部类权限也是不一样的。 最后，一定有人跳出来说用枚举实现单例，是的没错，枚举类很特殊，它在类加载的时候会初始化里面的所有的实例，而且 JVM 保证了它们不会再被实例化，所以它天生就是单例的。不说了，读者自己看着办吧，不建议使用。 建造者模式经常碰见的 XxxBuilder 的类，通常都是建造者模式的产物。建造者模式其实有很多的变种，但是对于客户端来说，我们的使用通常都是一个模式的： 12Food food = new FoodBuilder().a().b().c().build();Food food = Food.builder().a().b().c().build(); 套路就是先 new 一个 Builder，然后可以链式地调用一堆方法，最后再调用一次 build() 方法，我们需要的对象就有了。 来一个中规中矩的建造者模式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class User &#123; // 下面是“一堆”的属性 private String name; private String password; private String nickName; private int age; // 构造方法私有化，不然客户端就会直接调用构造方法了 private User(String name, String password, String nickName, int age) &#123; this.name = name; this.password = password; this.nickName = nickName; this.age = age; &#125; // 静态方法，用于生成一个 Builder，这个不一定要有，不过写这个方法是一个很好的习惯， // 有些代码要求别人写 new User.UserBuilder().a()...build() 看上去就没那么好 public static UserBuilder builder() &#123; return new UserBuilder(); &#125; public static class UserBuilder &#123; // 下面是和 User 一模一样的一堆属性 private String name; private String password; private String nickName; private int age; private UserBuilder() &#123; &#125; // 链式调用设置各个属性值，返回 this，即 UserBuilder public UserBuilder name(String name) &#123; this.name = name; return this; &#125; public UserBuilder password(String password) &#123; this.password = password; return this; &#125; public UserBuilder nickName(String nickName) &#123; this.nickName = nickName; return this; &#125; public UserBuilder age(int age) &#123; this.age = age; return this; &#125; // build() 方法负责将 UserBuilder 中设置好的属性“复制”到 User 中。 // 当然，可以在 “复制” 之前做点检验 public User build() &#123; if (name == null || password == null) &#123; throw new RuntimeException("用户名和密码必填"); &#125; if (age &lt;= 0 || age &gt;= 150) &#123; throw new RuntimeException("年龄不合法"); &#125; // 还可以做赋予”默认值“的功能 if (nickName == null) &#123; nickName = name; &#125; return new User(name, password, nickName, age); &#125; &#125;&#125; 代码核心是：先把所有的属性都设置给 Builder，然后 build() 方法的时候，将这些属性复制给实际产生的对象。 看看客户端的调用： 123456789public class APP &#123; public static void main(String[] args) &#123; User d = User.builder() .name("foo") .password("pAss12345") .age(25) .build(); &#125;&#125; 说实话，建造者模式的链式写法很吸引人，但是，多写了很多“无用”的 builder 的代码，感觉这个模式没什么用。不过，当属性很多，而且有些必填，有些选填的时候，这个模式会使代码清晰很多。我们可以在 Builder 的构造方法中强制让调用者提供必填字段，还有，在 build() 方法中校验各个参数比在 User 的构造方法中校验，代码要优雅一些。 题外话，强烈建议读者使用 lombok，用了 lombok 以后，上面的一大堆代码会变成如下这样: 1234567@Builderclass User &#123; private String name; private String password; private String nickName; private int age;&#125; 怎么样，省下来的时间是不是又可以干点别的了。当然，如果你只是想要链式写法，不想要建造者模式，有个很简单的办法，User 的 getter 方法不变，所有的 setter 方法都让其 return this 就可以了，然后就可以像下面这样调用： 1User user = new User().setName("").setPassword("").setAge(20); 原型模式这是我要说的创建型模式的最后一个设计模式了。 原型模式很简单：有一个原型实例，基于这个原型实例产生新的实例，也就是“克隆”了。 Object 类中有一个 clone() 方法，它用于生成一个新的对象，当然，如果我们要调用这个方法，java 要求我们的类必须先实现 Cloneable 接口，此接口没有定义任何方法，但是不这么做的话，在 clone() 的时候，会抛出 CloneNotSupportedException 异常。 1protected native Object clone() throws CloneNotSupportedException; java 的克隆是浅克隆，碰到对象引用的时候，克隆出来的对象和原对象中的引用将指向同一个对象。通常实现深克隆的方法是将对象进行序列化，然后再进行反序列化。 原型模式了解到这里我觉得就够了，各种变着法子说这种代码或那种代码是原型模式，没什么意义。 总结 创建型模式总体上比较简单，它们的作用就是为了产生实例对象，算是各种工作的第一步了，因为我们写的是面向对象的代码，所以我们第一步当然是需要创建一个对象了。 简单工厂模式最简单；工厂模式在简单工厂模式的基础上增加了选择工厂的维度，需要第一步选择合适的工厂；抽象工厂模式有产品族的概念，如果各个产品是存在兼容性问题的，就要用抽象工厂模式。 单例模式就不说了，为了保证全局使用的是同一对象，一方面是安全性考虑，一方面是为了节省资源； 建造者模式专门对付属性很多的那种类，为了让代码更优美； 原型模式用得最少，了解和 Object 类中的 clone() 方法相关的知识即可。 结构型模式前面创建型模式介绍了创建对象的一些设计模式，这节介绍的结构型模式旨在通过改变代码结构来达到解耦的目的，使得我们的代码容易维护和扩展。 代理模式第一个要介绍的代理模式是最常使用的模式之一了，用一个代理来隐藏具体实现类的实现细节，通常还用于在真实的实现的前后添加一部分逻辑。 既然说是代理，那就要对客户端隐藏真实实现，由代理来负责客户端的所有请求。当然，代理只是个代理，它不会完成实际的业务逻辑，而是一层皮而已，但是对于客户端来说，它必须表现得就是客户端需要的真实实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public interface FoodService &#123; Food makeChicken(); Food makeNoodle();&#125;public class FoodServiceImpl implements FoodService &#123; public Food makeChicken() &#123; Food f = new Chicken() f.setChicken("1kg"); f.setSpicy("1g"); f.setSalt("3g"); return f; &#125; public Food makeNoodle() &#123; Food f = new Noodle(); f.setNoodle("500g"); f.setSalt("5g"); return f; &#125;&#125;// 代理要表现得“就像是”真实实现类，所以需要实现 FoodServicepublic class FoodServiceProxy implements FoodService &#123; // 内部一定要有一个真实的实现类，当然也可以通过构造方法注入 private FoodService foodService = new FoodServiceImpl(); public Food makeChicken() &#123; System.out.println("我们马上要开始制作鸡肉了"); // 如果我们定义这句为核心代码的话，那么，核心代码是真实实现类做的， // 代理只是在核心代码前后做些“无足轻重”的事情 Food food = foodService.makeChicken(); System.out.println("鸡肉制作完成啦，加点胡椒粉"); // 增强 food.addCondiment("pepper"); return food; &#125; public Food makeNoodle() &#123; System.out.println("准备制作拉面~"); Food food = foodService.makeNoodle(); System.out.println("制作完成啦") return food; &#125;&#125; 客户端调用，注意，我们要用代理来实例化接口： 123// 这里用代理类来实例化FoodService foodService = new FoodServiceProxy();foodService.makeChicken(); 我们发现没有，代理模式说白了就是做 “方法包装” 或做 “方法增强”。在 AOP 中，其实就是动态代理的过程。比如 Spring 中，我们自己不定义代理类，但是 Spring 会帮我们动态来定义代理，然后把我们定义在 @Before、@After、@Around 中的代码逻辑动态添加到代理中。 说到动态代理，又可以展开说 …… Spring 中实现动态代理有两种，一种是如果我们的类定义了接口，如 UserService 接口和 UserServiceImpl 实现，那么采用 JDK 的动态代理，感兴趣的读者可以去看看 java.lang.reflect.Proxy 类的源码；另一种是我们自己没有定义接口的，Spring 会采用 CGLIB 进行动态代理，它是一个 jar 包，性能还不错。 适配器模式说完代理模式，说适配器模式，是因为它们很相似，这里可以做个比较。 适配器模式做的就是，有一个接口需要实现，但是我们现成的对象都不满足，需要加一层适配器来进行适配。 适配器模式总体来说分三种：默认适配器模式、对象适配器模式、类适配器模式。先不急着分清楚这几个，先看看例子再说。 默认适配器模式首先，我们先看看最简单的适配器模式默认适配器模式(Default Adapter)是怎么样的。 我们用 Appache commons-io 包中的 FileAlterationListener 做例子，此接口定义了很多的方法，用于对文件或文件夹进行监控，一旦发生了对应的操作，就会触发相应的方法。 12345678910public interface FileAlterationListener &#123; void onStart(final FileAlterationObserver observer); void onDirectoryCreate(final File directory); void onDirectoryChange(final File directory); void onDirectoryDelete(final File directory); void onFileCreate(final File file); void onFileChange(final File file); void onFileDelete(final File file); void onStop(final FileAlterationObserver observer);&#125; 此接口的一大问题是抽象方法太多了，如果我们要用这个接口，意味着我们要实现每一个抽象方法，如果我们只是想要监控文件夹中的文件创建和文件删除事件，可是我们还是不得不实现所有的方法，很明显，这不是我们想要的。 所以，我们需要下面的一个适配器，它用于实现上面的接口，但是所有的方法都是空方法，这样，我们就可以转而定义自己的类来继承下面这个类即可。 1234567891011121314151617181920212223242526public class FileAlterationListenerAdaptor implements FileAlterationListener &#123; public void onStart(final FileAlterationObserver observer) &#123; &#125; public void onDirectoryCreate(final File directory) &#123; &#125; public void onDirectoryChange(final File directory) &#123; &#125; public void onDirectoryDelete(final File directory) &#123; &#125; public void onFileCreate(final File file) &#123; &#125; public void onFileChange(final File file) &#123; &#125; public void onFileDelete(final File file) &#123; &#125; public void onStop(final FileAlterationObserver observer) &#123; &#125;&#125; 比如我们可以定义以下类，我们仅仅需要实现我们想实现的方法就可以了： 1234567891011public class FileMonitor extends FileAlterationListenerAdaptor &#123; public void onFileCreate(final File file) &#123; // 文件创建 doSomething(); &#125; public void onFileDelete(final File file) &#123; // 文件删除 doSomething(); &#125;&#125; 当然，上面说的只是适配器模式的其中一种，也是最简单的一种，无需多言。下面，再介绍“正统的”适配器模式。 对象适配器模式来看一个《Head First 设计模式》中的一个例子，我稍微修改了一下，看看怎么将鸡适配成鸭，这样鸡也能当鸭来用。 因为，现在鸭这个接口，我们没有合适的实现类可以用，所以需要适配器。 12345678910111213141516171819public interface Duck &#123; public void quack(); // 鸭的呱呱叫 public void fly(); // 飞&#125;public interface Cock &#123; public void gobble(); // 鸡的咕咕叫 public void fly(); // 飞&#125;public class WildCock implements Cock &#123; public void gobble() &#123; System.out.println("咕咕叫"); &#125; public void fly() &#123; System.out.println("鸡也会飞哦"); &#125;&#125; 鸭接口有 fly() 和 quare() 两个方法，鸡 Cock 如果要冒充鸭，fly() 方法是现成的，但是鸡不会鸭的呱呱叫，没有 quack() 方法。这个时候就需要适配了： 123456789101112131415161718192021// 毫无疑问，首先，这个适配器肯定需要 implements Duck，这样才能当做鸭来用public class CockAdapter implements Duck &#123; Cock cock; // 构造方法中需要一个鸡的实例，此类就是将这只鸡适配成鸭来用 public CockAdapter(Cock cock) &#123; this.cock = cock; &#125; // 实现鸭的呱呱叫方法 @Override public void quack() &#123; // 内部其实是一只鸡的咕咕叫 cock.gobble(); &#125; @Override public void fly() &#123; cock.fly(); &#125;&#125; 客户端调用很简单了： 1234567public static void main(String[] args) &#123; // 有一只野鸡 Cock wildCock = new WildCock(); // 成功将野鸡适配成鸭 Duck duck = new CockAdapter(wildCock); ...&#125; 到这里，大家也就知道了适配器模式是怎么回事了。无非是我们需要一只鸭，但是我们只有一只鸡，这个时候就需要定义一个适配器，由这个适配器来充当鸭，但是适配器里面的方法还是由鸡来实现的。 我们用一个图来简单说明下： 上图应该还是很容易理解的，我就不做更多的解释了。下面，我们看看类适配模式怎么样的。 类适配器模式废话少说，直接上图： 看到这个图，大家应该很容易理解的吧，通过继承的方法，适配器自动获得了所需要的大部分方法。这个时候，客户端使用更加简单，直接 1Target t = new SomeAdapter(); 就可以了。 适配器模式总结 类适配和对象适配的异同 一个采用继承，一个采用组合；类适配属于静态实现，对象适配属于组合的动态实现，对象适配需要多实例化一个对象。总体来说，对象适配用得比较多。 适配器模式和代理模式的异同比较这两种模式，其实是比较对象适配器模式和代理模式，在代码结构上，它们很相似，都需要一个具体的实现类的实例。但是它们的目的不一样: 代理模式做的是增强原方法的活； 适配器做的是适配的活，为的是提供“把鸡包装成鸭，然后当做鸭来使用”，而鸡和鸭它们之间原本没有继承关系。 桥梁模式理解桥梁模式，其实就是理解代码抽象和解耦。 我们首先需要一个桥梁，它是一个接口，定义提供的接口方法。 123public interface DrawAPI &#123; public void draw(int radius, int x, int y);&#125; 然后是一系列实现类： 1234567891011121314151617181920public class RedPen implements DrawAPI &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println("用红色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125;public class GreenPen implements DrawAPI &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println("用绿色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125;public class BluePen implements DrawAPI &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println("用蓝色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125; 定义一个抽象类，此类的实现类都需要使用 DrawAPI： 12345678public abstract class Shape &#123; protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI)&#123; this.drawAPI = drawAPI; &#125; public abstract void draw(); &#125; 定义抽象类的子类： 12345678910111213141516171819202122232425262728// 圆形public class Circle extends Shape &#123; private int radius; public Circle(int radius, DrawAPI drawAPI) &#123; super(drawAPI); this.radius = radius; &#125; public void draw() &#123; drawAPI.draw(radius, 0, 0); &#125;&#125;// 长方形public class Rectangle extends Shape &#123; private int x; private int y; public Rectangle(int x, int y, DrawAPI drawAPI) &#123; super(drawAPI); this.x = x; this.y = y; &#125; public void draw() &#123; drawAPI.draw(0, x, y); &#125;&#125; 最后，我们来看客户端演示： 1234567public static void main(String[] args) &#123; Shape greenCircle = new Circle(10, new GreenPen()); Shape redRectangle = new Rectangle(4, 8, new RedPen()); greenCircle.draw(); redRectangle.draw();&#125; 可能大家看上面一步步还不是特别清晰，我把所有的东西整合到一张图上： 这回大家应该就知道抽象在哪里，怎么解耦了吧。桥梁模式的优点也是显而易见的，就是非常容易进行扩展。 装饰模式要把装饰模式说清楚明白，不是件容易的事情。也许读者知道 Java IO 中的几个类是典型的装饰模式的应用，但是读者不一定清楚其中的关系，也许看完就忘了，希望看完这节后，读者可以对其有更深的感悟。 首先，我们先看一个简单的图，看这个图的时候，了解下层次结构就可以了： 我们来说说装饰模式的出发点，从图中可以看到，接口 Component 其实已经有了 ConcreteComponentA 和 ConcreteComponentB 两个实现类了，但是，如果我们要增强这两个实现类的话，我们就可以采用装饰模式，用具体的装饰器来装饰实现类，以达到增强的目的。 从名字来简单解释下装饰器。既然说是装饰，那么往往就是添加小功能这种，而且，我们要满足可以添加多个小功能。最简单的，代理模式就可以实现功能的增强，但是代理不容易实现多个功能的增强，当然你可以说用代理包装代理的方式，但是那样的话代码就复杂了。 首先明白一些简单的概念，从图中我们看到，所有的具体装饰者们 ConcreteDecorator 都可以作为 Component 来使用，因为它们都实现了 Component 中的所有接口。它们和 Component 实现类 ConcreteComponent 的区别是，它们只是装饰者，起装饰作用，也就是即使它们看上去牛逼轰轰，但是它们都只是在具体的实现中加了层皮来装饰而已。 注意这段话中混杂在各个名词中的 Component 和 Decorator，别搞混了。 下面来看看一个例子，先把装饰模式弄清楚，然后再介绍下 java io 中的装饰模式的应用。 最近大街上流行起来了“快乐柠檬”，我们把快乐柠檬的饮料分为三类：红茶、绿茶、咖啡，在这三大类的基础上，又增加了许多的口味，什么金桔柠檬红茶、金桔柠檬珍珠绿茶、芒果红茶、芒果绿茶、芒果珍珠红茶、烤珍珠红茶、烤珍珠芒果绿茶、椰香胚芽咖啡、焦糖可可咖啡等等，每家店都有很长的菜单，但是仔细看下，其实原料也没几样，但是可以搭配出很多组合，如果顾客需要，很多没出现在菜单中的饮料他们也是可以做的。 在这个例子中，红茶、绿茶、咖啡是最基础的饮料，其他的像金桔柠檬、芒果、珍珠、椰果、焦糖等都属于装饰用的。当然，在开发中，我们确实可以像门店一样，开发这些类：LemonBlackTea、LemonGreenTea、MangoBlackTea、MangoLemonGreenTea……但是，很快我们就发现，这样子干肯定是不行的，这会导致我们需要组合出所有的可能，而且如果客人需要在红茶中加双份柠檬怎么办？三份柠檬怎么办？万一有个变态要四份柠檬，所以这种做法是给自己找加班的。 不说废话了，上代码。首先，定义饮料抽象基类： 123456public abstract class Beverage &#123; // 返回描述 public abstract String getDescription(); // 返回价格 public abstract double cost();&#125; 然后是三个基础饮料实现类，红茶、绿茶和咖啡： 12345678910111213141516171819public class BlackTea extends Beverage &#123; public String getDescription() &#123; return "红茶"; &#125; public double cost() &#123; return 10; &#125;&#125;public class GreenTea extends Beverage &#123; public String getDescription() &#123; return "绿茶"; &#125; public double cost() &#123; return 11; &#125;&#125;...// 咖啡省略 定义调料，也就是装饰者的基类，此类必须继承自 Beverage： 1234// 调料public abstract class Condiment extends Beverage &#123;&#125; 然后我们来定义柠檬、芒果等具体的调料，它们属于装饰者，毫无疑问，这些调料肯定都需要继承 Condiment 类： 1234567891011121314151617181920212223242526272829303132333435public class Lemon extends Condiment &#123; // 这里很关键，需要传入具体的饮料，如需要传入没有被装饰的红茶或绿茶， // 当然也可以传入已经装饰好的芒果绿茶，这样可以做芒果柠檬绿茶 private Beverage bevarage; public Lemon(Beverage bevarage) &#123; this.bevarage = bevarage; &#125; public String getDescription() &#123; // 装饰 return bevarage.getDescription() + ", 加柠檬"; &#125; public double cost() &#123; // 装饰 return beverage.cost() + 2; // 加柠檬需要 2 元 &#125;&#125;public class Mango extends Condiment &#123; private Beverage bevarage; public Mango(Beverage bevarage) &#123; this.bevarage = bevarage; &#125; public String getDescription() &#123; return bevarage.getDescription() + ", 加芒果"; &#125; public double cost() &#123; return beverage.cost() + 3; // 加芒果需要 3 元 &#125;&#125;...// 给每一种调料都加一个类 看客户端调用： 12345678910public static void main(String[] args) &#123; // 首先，我们需要一个基础饮料，红茶、绿茶或咖啡 Beverage beverage = new GreenTea(); // 开始装饰 beverage = new Lemon(beverage); // 先加一份柠檬 beverage = new Mongo(beverage); // 再加一份芒果 System.out.println(beverage.getDescription() + " 价格：￥" + beverage.cost()); //"绿茶, 加柠檬, 加芒果 价格：￥16"&#125; 如果我们需要芒果珍珠双份柠檬红茶： 1Beverage beverage = new Mongo(new Pearl(new Lemon(new Lemon(new BlackTea())))); 是不是很变态？看看下图可能会清晰一些： 到这里，大家应该已经清楚装饰模式了吧。 下面，我们再来说说 java IO 中的装饰模式。看下图 InputStream 派生出来的部分类： 我们知道 InputStream 代表了输入流，具体的输入来源可以是文件（FileInputStream）、管道（PipedInputStream）、数组（ByteArrayInputStream）等，这些就像前面奶茶的例子中的红茶、绿茶，属于基础输入流。 FilterInputStream 承接了装饰模式的关键节点，其实现类是一系列装饰器，比如： BufferedInputStream 代表用缓冲来装饰，也就使得输入流具有了缓冲的功能 LineNumberInputStream 代表用行号来装饰，在操作的时候就可以取得行号了 DataInputStream 的装饰，使得我们可以从输入流转换为 java 中的基本类型值 当然，在 java IO 中，如果我们使用装饰器的话，就不太适合面向接口编程了，如： 123LineNumberInputStream is = new LineNumberInputStream( new BufferedInputStream( new FileInputStream(""))); InputStream 还是不具有读取行号的功能，因为读取行号的方法定义在 LineNumberInputStream 类中。 门面模式门面模式（也叫外观模式，Facade Pattern）在许多源码中有使用，比如 slf4j 就可以理解为是门面模式的应用。这是一个简单的设计模式，我们直接上代码再说吧。 首先，我们定义一个接口： 123public interface Shape &#123; void draw();&#125; 定义几个实现类： 123456789101112131415public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println("Circle::draw()"); &#125;&#125;public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println("Rectangle::draw()"); &#125;&#125; 客户端调用： 123456789public static void main(String[] args) &#123; // 画一个圆形 Shape circle = new Circle(); circle.draw(); // 画一个长方形 Shape rectangle = new Rectangle(); rectangle.draw();&#125; 以上是我们常写的代码，我们需要画圆就要先实例化圆，画长方形就需要先实例化一个长方形，然后再调用相应的 draw() 方法。 下面，我们看看怎么用门面模式来让客户端调用更加友好一些。我们先定义一个门面： 12345678910111213141516171819202122232425public class ShapeMaker &#123; private Shape circle; private Shape rectangle; private Shape square; public ShapeMaker() &#123; circle = new Circle(); rectangle = new Rectangle(); square = new Square(); &#125; /** * 下面定义一堆方法，具体应该调用什么方法，由这个门面来决定 */ public void drawCircle()&#123; circle.draw(); &#125; public void drawRectangle()&#123; rectangle.draw(); &#125; public void drawSquare()&#123; square.draw(); &#125;&#125; 看看现在客户端怎么调用： 12345678public static void main(String[] args) &#123; ShapeMaker shapeMaker = new ShapeMaker(); // 客户端调用现在更加清晰了 shapeMaker.drawCircle(); shapeMaker.drawRectangle(); shapeMaker.drawSquare(); &#125; 门面模式的优点显而易见，客户端不再需要关注实例化时应该使用哪个实现类，直接调用门面提供的方法就可以了，因为门面类提供的方法的方法名对于客户端来说已经很友好了。 组合模式组合模式用于表示具有层次结构的数据，使得我们对单个对象和组合对象的访问具有一致性。 直接看一个例子吧，每个员工都有姓名、部门、薪水这些属性，同时还有下属员工集合（虽然可能集合为空），而下属员工和自己的结构是一样的，也有姓名、部门这些属性，同时也有他们的下属员工集合。 1234567891011121314151617181920212223242526272829public class Employee &#123; private String name; private String dept; private int salary; private List&lt;Employee&gt; subordinates; // 下属 public Employee(String name,String dept, int sal) &#123; this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;Employee&gt;(); &#125; public void add(Employee e) &#123; subordinates.add(e); &#125; public void remove(Employee e) &#123; subordinates.remove(e); &#125; public List&lt;Employee&gt; getSubordinates()&#123; return subordinates; &#125; public String toString()&#123; return ("Employee :[ Name : " + name + ", dept : " + dept + ", salary :" + salary+" ]"); &#125; &#125; 通常，这种类需要定义 add(node)、remove(node)、getChildren()这些方法。这说的其实就是组合模式。 享元模式英文是 Flyweight Pattern，不知道是谁最先翻译的这个词，感觉这翻译真的不好理解，我们试着强行关联起来吧。 Flyweight 是轻量级的意思，享元分开来说就是 共享元器件，也就是复用已经生成的对象，这种做法当然也就是轻量级的了。 复用对象最简单的方式是，用一个 HashMap 来存放每次新生成的对象。每次需要一个对象的时候，先到 HashMap 中看看有没有，如果没有，再生成新的对象，然后将这个对象放入 HashMap 中。 总结前面，我们说了代理模式、适配器模式、桥梁模式、装饰模式、门面模式、组合模式和享元模式。 代理模式是做方法增强的 适配器模式是把鸡包装成鸭这种用来适配接口的 桥梁模式做到了很好的解耦 装饰模式从名字上就看得出来，适合于装饰类或者说是增强类的场景 门面模式的优点是客户端不需要关心实例化过程，只要调用需要的方法即可 组合模式用于描述具有层次结构的数据 享元模式是为了在特定的场景中缓存已经创建的对象，用于提高性能 行为型模式行为型模式关注的是各个类之间的相互作用，将职责划分清楚，使得我们的代码更加地清晰。 策略模式策略模式太常用了，所以把它放到最前面进行介绍。它比较简单，我就不废话，直接用代码说事吧。 下面设计的场景是，我们需要画一个图形，可选的策略就是用红色笔来画，还是绿色笔来画，或者蓝色笔来画。首先，先定义一个策略接口： 123public interface Strategy &#123; public void draw(int radius, int x, int y);&#125; 然后我们定义具体的几个策略： 1234567891011121314151617181920public class RedPen implements Strategy &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println("用红色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125;public class GreenPen implements Strategy &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println("用绿色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125;public class BluePen implements Strategy &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println("用蓝色笔画图，radius:" + radius + ", x:" + x + ", y:" + y); &#125;&#125; 使用策略的类： 1234567891011public class Context &#123; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeDraw(int radius, int x, int y)&#123; return strategy.draw(radius, x, y); &#125;&#125; 客户端演示： 1234public static void main(String[] args) &#123; Context context = new Context(new BluePen()); // 使用绿色笔来画 context.executeDraw(10, 0, 0);&#125; 放到一张图上，让大家看得清晰些： 这个时候，大家有没有联想到结构型模式中的桥梁模式，它们其实非常相似，我把桥梁模式的图拿过来大家对比下： 要我说的话，它们非常相似，桥梁模式在左侧加了一层抽象而已。桥梁模式的耦合更低，结构更复杂一些。 观察者模式观察者模式对于我们来说，真是再简单不过了。无外乎两个操作，观察者订阅自己关心的主题和主题有数据变化后通知观察者们。 首先，需要定义主题，每个主题需要持有观察者列表的引用，用于在数据变更的时候通知各个观察者： 1234567891011121314151617181920212223242526public class Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(); private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; // 数据已变更，通知观察者们 notifyAllObservers(); &#125; public void attach(Observer observer)&#123; observers.add(observer); &#125; // 通知观察者们 public void notifyAllObservers()&#123; for (Observer observer : observers) &#123; observer.update(); &#125; &#125; &#125; 定义观察者接口： 1234public abstract class Observer &#123; protected Subject subject; public abstract void update();&#125; 其实如果只有一个观察者类的话，接口都不用定义了，不过，通常场景下，既然用到了观察者模式，我们就是希望一个事件出来了，会有多个不同的类需要处理相应的信息。比如，订单修改成功事件，我们希望发短信的类得到通知、发邮件的类得到通知、处理物流信息的类得到通知等。 我们来定义具体的几个观察者类： 123456789101112131415161718192021222324252627282930public class BinaryObserver extends Observer &#123; // 在构造方法中进行订阅主题 public BinaryObserver(Subject subject) &#123; this.subject = subject; // 通常在构造方法中将 this 发布出去的操作一定要小心 this.subject.attach(this); &#125; // 该方法由主题类在数据变更的时候进行调用 @Override public void update() &#123; String result = Integer.toBinaryString(subject.getState()); System.out.println("订阅的数据发生变化，新的数据处理为二进制值为：" + result); &#125;&#125;public class HexaObserver extends Observer &#123; public HexaObserver(Subject subject) &#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; String result = Integer.toHexString(subject.getState()).toUpperCase(); System.out.println("订阅的数据发生变化，新的数据处理为十六进制值为：" + result); &#125;&#125; 客户端使用也非常简单： 12345678910public static void main(String[] args) &#123; // 先定义一个主题 Subject subject1 = new Subject(); // 定义观察者 new BinaryObserver(subject1); new HexaObserver(subject1); // 模拟数据变更，这个时候，观察者们的 update 方法将会被调用 subject.setState(11);&#125; output: 12订阅的数据发生变化，新的数据处理为二进制值为：1011订阅的数据发生变化，新的数据处理为十六进制值为：B 当然，jdk 也提供了相似的支持，具体的大家可以参考 java.util.Observable 和 java.util.Observer 这两个类。实际生产过程中，观察者模式往往用消息中间件来实现，如果要实现单机观察者模式，笔者建议读者使用 Guava 中的 EventBus，它有同步实现也有异步实现，本文主要介绍设计模式，就不展开说了。 责任链模式责任链通常需要先建立一个单向链表，然后调用方只需要调用头部节点就可以了，后面会自动流转下去。比如流程审批就是一个很好的例子，只要终端用户提交申请，根据申请的内容信息，自动建立一条责任链，然后就可以开始流转了。 有这么一个场景，用户参加一个活动可以领取奖品，但是活动需要进行很多的规则校验然后才能放行，比如首先需要校验用户是否是新用户、今日参与人数是否有限额、全场参与人数是否有限额等等。设定的规则都通过后，才能让用户领走奖品。 如果产品给你这个需求的话，我想大部分人一开始肯定想的就是，用一个 List 来存放所有的规则，然后 foreach 执行一下每个规则就好了。不过，读者也先别急，看看责任链模式和我们说的这个有什么不一样？ 首先，我们要定义流程上节点的基类： 1234567891011121314public abstract class RuleHandler &#123; // 后继节点 protected RuleHandler successor; public abstract void apply(Context context); public void setSuccessor(RuleHandler successor) &#123; this.successor = successor; &#125; public RuleHandler getSuccessor() &#123; return successor; &#125;&#125; 接下来，我们需要定义具体的每个节点了。 校验用户是否是新用户： 1234567891011121314public class NewUserRuleHandler extends RuleHandler &#123; public void apply(Context context) &#123; if (context.isNewUser()) &#123; // 如果有后继节点的话，传递下去 if (this.getSuccessor() != null) &#123; this.getSuccessor().apply(context); &#125; &#125; else &#123; throw new RuntimeException("该活动仅限新用户参与"); &#125; &#125;&#125; 校验用户所在地区是否可以参与： 123456789101112public class LocationRuleHandler extends RuleHandler &#123; public void apply(Context context) &#123; boolean allowed = activityService.isSupportedLocation(context.getLocation); if (allowed) &#123; if (this.getSuccessor() != null) &#123; this.getSuccessor().apply(context); &#125; &#125; else &#123; throw new RuntimeException("非常抱歉，您所在的地区无法参与本次活动"); &#125; &#125;&#125; 校验奖品是否已领完： 123456789101112public class LimitRuleHandler extends RuleHandler &#123; public void apply(Context context) &#123; int remainedTimes = activityService.queryRemainedTimes(context); // 查询剩余奖品 if (remainedTimes &gt; 0) &#123; if (this.getSuccessor() != null) &#123; this.getSuccessor().apply(userInfo); &#125; &#125; else &#123; throw new RuntimeException("您来得太晚了，奖品被领完了"); &#125; &#125;&#125; 客户端： 123456789public static void main(String[] args) &#123; RuleHandler newUserHandler = new NewUserRuleHandler(); RuleHandler locationHandler = new LocationRuleHandler(); RuleHandler limitHandler = new LimitRuleHandler(); // 假设本次活动仅校验地区和奖品数量，不校验新老用户 locationHandler.setSuccessor(limitHandler); locationHandler.apply(context);&#125; 代码其实很简单，就是先定义好一个链表，然后在通过任意一节点后，如果此节点有后继节点，那么传递下去。 模板方法模式在含有继承结构的代码中，模板方法模式是非常常用的，这也是在开源代码中大量被使用的。通常会有一个抽象类： 123456789101112131415public abstract class AbstractTemplate &#123; // 这就是模板方法 public void templateMethod()&#123; init(); apply(); // 这个是重点 end(); // 可以作为钩子方法 &#125; protected void init() &#123; System.out.println("init 抽象层已经实现，子类也可以选择覆写"); &#125; // 留给子类实现 protected abstract void apply(); protected void end() &#123; &#125;&#125; 模板方法中调用了 3 个方法，其中 apply() 是抽象方法，子类必须实现它，其实模板方法中有几个抽象方法完全是自由的，我们也可以将三个方法都设置为抽象方法，让子类来实现。 也就是说，模板方法只负责定义第一步应该要做什么，第二步应该做什么，第三步应该做什么，至于怎么做，由子类来实现。 我们写一个实现类： 12345678public class ConcreteTemplate extends AbstractTemplate &#123; public void apply() &#123; System.out.println("子类实现抽象方法 apply"); &#125; public void end() &#123; System.out.println("我们可以把 method3 当做钩子方法来使用，需要的时候覆写就可以了"); &#125;&#125; 客户端调用演示： 12345public static void main(String[] args) &#123; AbstractTemplate t = new ConcreteTemplate(); // 调用模板方法 t.templateMethod();&#125; 代码其实很简单，基本上看到就懂了，关键是要学会用到自己的代码中。 状态模式我们说一个简单的例子。商品库存中心有个最基本的需求是减库存和补库存，我们看看怎么用状态模式来写。 核心在于，我们的关注点不再是 Context 是该进行哪种操作，而是关注在这个 Context 会有哪些操作。定义状态接口： 123public interface State &#123; public void doAction(Context context);&#125; 定义减库存的状态： 12345678910111213public class DeductState implements State &#123; public void doAction(Context context) &#123; System.out.println("商品卖出，准备减库存"); context.setState(this); //... 执行减库存的具体操作 &#125; public String toString()&#123; return "Deduct State"; &#125;&#125; 定义补库存状态： 1234567891011public class RevertState implements State &#123; public void doAction(Context context) &#123; System.out.println("给此商品补库存"); context.setState(this); //... 执行加库存的具体操作 &#125; public String toString() &#123; return "Revert State"; &#125;&#125; 前面用到了 context.setState(this)，我们来看看怎么定义 Context 类： 1234567891011121314public class Context &#123; private State state; private String name; public Context(String name) &#123; this.name = name; &#125; public void setState(State state) &#123; this.state = state; &#125; public void getState() &#123; return this.state; &#125;&#125; 我们来看下客户端调用，大家就一清二楚了： 123456789101112131415public static void main(String[] args) &#123; // 我们需要操作的是 iPhone X Context context = new Context("iPhone X"); // 看看怎么进行补库存操作 State revertState = new RevertState(); revertState.doAction(context); // 同样的，减库存操作也非常简单 State deductState = new DeductState(); deductState.doAction(context); // 如果需要我们可以获取当前的状态 // context.getState().toString();&#125; 读者可能会发现，在上面这个例子中，如果我们不关心当前 context 处于什么状态，那么 Context 就可以不用维护 state 属性了，那样代码会简单很多。不过，商品库存这个例子毕竟只是个例，我们还有很多实例是需要知道当前 context 处于什么状态的。 总结行为型模式部分介绍了策略模式、观察者模式、责任链模式、模板方法模式和状态模式，其实，经典的行为型模式还包括备忘录模式、命令模式等，但是它们的使用场景比较有限，而且本文篇幅也挺大了，这里不进行介绍了。 转载&amp;参考 【转载】 https://juejin.im/post/5bc96afff265da0aa94a4493【参考】 https://www.tutorialspoint.com/design_pattern/index.htm]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper概念介绍]]></title>
    <url>%2F2019%2F07%2F12%2FZookeeper%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Zookeeper简介概念Zookeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。 后来，Apache ZooKeeper成为Hadoop，HBase和其他分布式框架使用的有组织服务的标准。 例如，Apache HBase使用ZooKeeper跟踪分布式数据的状态。ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。 名字由来Zookeeper名字的由来是比较有趣的，下面的片段摘抄自《从PAXOS到ZOOKEEPER分布式一致性原理与实践》一书： Zookeeper最早起源于雅虎的研究院的一个研究小组。在立项初期，考虑到很多项目都是用动物的名字来命名的(例如著名的Pig项目)，雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家Raghu Ramakrishnan开玩笑说：再这样下去，我们这儿就变成动物园了。此话一出，大家纷纷表示就叫动物园管理员吧——因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper正好用来进行分布式环境的协调——于是，Zookeeper的名字由此诞生了。 Curator无疑是Zookeeper客户端中的瑞士军刀，它译作”馆长”或者’’管理者’’，不知道是不是开发小组有意而为之，笔者猜测有可能这样命名的原因是说明Curator就是Zookeeper的馆长(脑洞有点大：Curator就是动物园的园长)。 应用场景 ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。 ZooKeeper的一些概念会话（Session）Session 指的是 ZooKeeper 服务器与客户端会话。在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP长连接。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。 通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session的sessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。 在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。 Znode在谈到分布式的时候，我们通常说的“节点”是指组成集群的每一台机器。然而，在Zookeeper中，“节点”分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。 Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。 在Zookeeper中，node可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。 另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：SEQUENTIAL。 一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。 版本Zookeeper 的每个 ZNode 上都会存储数据，对应于每个ZNode，Zookeeper 都会为其维护一个叫作 Stat 的数据结构，Stat中记录了这个 ZNode 的三个数据版本，分别是： version（当前ZNode数据内容的版本号） cversion（当前ZNode子节点的版本号 aversion（当前ZNode的ACL变更版本号） 特别说明： ZK 中版本就是修改次数：即使修改前后，内容不变，但版本仍会+1： version=0 表示节点创建之后，修改的次数为 0。 cversion 子节点列表：ZNode，其中 cversion 只会感知子节点列表变更信息，新增子节点、删除子节点，而不会感知子节点数据内容的变更。 目标：解决 ZNode 的并发更新问题，实现 CAS（Compare And Switch）乐观锁。 WatcherWatcher（事件监听器），是Zookeeper中的一个很重要的特性。Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。 ACLZookeeper采用ACL（Access-Control-Lists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了如下5种权限。 CREATE: 能创建子节点 READ：能获取节点数据和列出其子节点 WRITE: 能设置节点数据 DELETE: 能删除子节点 ADMIN: 能设置ACL权限 其中尤其需要注意的是，CREATE和DELETE这两种权限都是针对子节点的权限控制. 重要概念总结 ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。 ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。 ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。） ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。 ZooKeeper 底层其实只提供了两个功能：①管理（存储、读取）用户程序提交的数据；②为用户程序提交数据节点监听服务。 Zookeeper特性 节点类型： 临时节点：客户端和服务端之间的Session过期之后节点会自动消失。 持久节点：创建节点之后，节点就会一直存在，除非手动删除。 临时顺序节点：拥有临时节点的特性，同时会根据创建的顺序给节点添加一个编号（编号作为节点名字的一部分）。 持久顺序节点：拥有持久节点的特性，同时会根据创建的顺序给节点添加一个编号（编号作为节点名字的一部分）。 原子性： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。 单一系统映像： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。 可靠性： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。 Watcher机制：节点数据变更注册时，在该节点的Watcher都会被通知。子节点列表变化注册该节点的Watcher也会被通知。 多个客户端同时创建一个节点，保证只有一个客户端可以创建成功。 对于有N台服务器组成的集群，保证有小于等于（N/2）-1 台服务器不能提供服务时，集群的数据仍然保持完整。 ZooKeeper 设计目标简单的数据模型ZooKeeper 允许分布式进程通过共享的层次结构命名空间进行相互协调，这与标准文件系统类似。 名称空间由 ZooKeeper 中的数据寄存器组成 - 称为znode，这些类似于文件和目录。 与为存储设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量和低延迟。 可构建集群为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的。 客户端在使用 ZooKeeper 时，需要知道集群机器列表，通过与集群中的某一台机器建立 TCP 连接来使用服务，客户端使用这个TCP链接来发送请求、获取结果、获取监听事件以及发送心跳包。如果这个连接异常断开了，客户端可以连接到另外的机器上。 ZooKeeper 官方提供的架构图： 上图中每一个Server代表一个安装Zookeeper服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 Zab 协议（Zookeeper Atomic Broadcast）来保持数据的一致性。 顺序访问对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。 这个编号也叫做时间戳——zxid（Zookeeper Transaction Id） ZooKeeper 集群角色介绍最典型集群模式： Master/Slave 模式（主备模式）。在这种模式中，通常 Master服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。 但是，在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了Leader、Follower 和 Observer 三种角色。如下图所示 ZooKeeper 集群中的所有机器通过一个 Leader 选举过程来选定一台称为 “Leader” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。 除了 Leader 外，Follower 和 Observer 都只能提供读服务。 Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。]]></content>
      <categories>
        <category>基本知识</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-Boot + Zookeeper(Curator)实现分布式锁]]></title>
    <url>%2F2019%2F07%2F12%2FSpring-Boot-Zookeeper-Curator-%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[Curator简介Apache Curator是Netflix公司开源的一个Zookeeper客户端，目前已经是Apache的顶级项目，与Zookeeper提供的原生客户端相比，Curator的抽象层次更高，简化了Zookeeper客户端的开发量，通过封装的一套高级API，里面提供了更多丰富的操作，例如session超时重连、主从选举、分布式计数器、分布式锁等等适用于各种复杂场景的zookeeper操作。本文介绍如果通过Zookeeper实现一个分布式锁。 代码结构 核心依赖123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt; 配置文件1234567891011server.port=8012#重试次数curator.retryCount=5#重试间隔时间curator.elapsedTimeMs=5000# zookeeper 地址curator.connectString=10.101.38.213:8181# session超时时间curator.sessionTimeoutMs=60000# 连接超时时间curator.connectionTimeoutMs=5000 初始化ZK-Client1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.austin.brant.zk.demo.config;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.retry.RetryNTimes;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * curator配置 * * @author austin-brant * @since 2019/7/12 17:03 */@Configurationpublic class CuratorConfiguration &#123; @Value("$&#123;curator.retryCount&#125;") private int retryCount; @Value("$&#123;curator.elapsedTimeMs&#125;") private int elapsedTimeMs; @Value("$&#123;curator.connectString&#125;") private String connectString; @Value("$&#123;curator.sessionTimeoutMs&#125;") private int sessionTimeoutMs; @Value("$&#123;curator.connectionTimeoutMs&#125;") private int connectionTimeoutMs; @Bean(name = "curatorFramework", initMethod = "start") public CuratorFramework curatorFramework() &#123; return CuratorFrameworkFactory.newClient( connectString, sessionTimeoutMs, connectionTimeoutMs, new RetryNTimes(retryCount, elapsedTimeMs) ); &#125;&#125; 分布式锁实现类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132package com.austin.brant.zk.demo.utils;import java.util.concurrent.CountDownLatch;import javax.annotation.Resource;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.recipes.cache.PathChildrenCache;import org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent;import org.apache.curator.framework.recipes.cache.PathChildrenCacheListener;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.ZooDefs;import org.springframework.beans.factory.InitializingBean;import org.springframework.stereotype.Service;import lombok.extern.slf4j.Slf4j;/** * 基于zk的分布锁实现 * * @author austin-brant * @since 2019/7/12 17:17 */@Slf4j@Servicepublic class DistributedLockByZk implements InitializingBean &#123; private final static String ROOT_PATH_LOCK = "rootlock"; private CountDownLatch countDownLatch = new CountDownLatch(1); @Resource(name = "curatorFramework") private CuratorFramework curatorFramework; /** * 获取分布式锁 */ public void acquireDistributedLock(String path) &#123; String keyPath = "/" + ROOT_PATH_LOCK + "/" + path; while (true) &#123; try &#123; curatorFramework .create() .creatingParentsIfNeeded() .withMode(CreateMode.EPHEMERAL) // 临时节点 .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) .forPath(keyPath); log.info("success to acquire lock for path:&#123;&#125;", keyPath); break; &#125; catch (Exception e) &#123; log.info("failed to acquire lock for path:&#123;&#125;", keyPath); log.info("while try again ......."); if (countDownLatch.getCount() &lt;= 0) &#123; countDownLatch = new CountDownLatch(1); &#125; try &#123; // 阻塞等待锁释放，重新获取 countDownLatch.wait(); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; &#125; &#125; &#125; /** * 释放分布式锁 */ public boolean releaseDistributedLock(String path) &#123; String keyPath = "/" + ROOT_PATH_LOCK + "/" + path; try &#123; if (curatorFramework.checkExists().forPath(keyPath) != null) &#123; curatorFramework.delete().forPath(keyPath); &#125; &#125; catch (Exception e) &#123; log.error("failed to release lock"); return false; &#125; return true; &#125; /** * 创建 watcher 事件 */ private void addWatcher(String path) throws Exception &#123; String keyPath; if (path.equals(ROOT_PATH_LOCK)) &#123; keyPath = "/" + path; &#125; else &#123; keyPath = "/" + ROOT_PATH_LOCK + "/" + path; &#125; final PathChildrenCache cache = new PathChildrenCache(curatorFramework, keyPath, false); cache.start(PathChildrenCache.StartMode.POST_INITIALIZED_EVENT); cache.getListenable().addListener(new PathChildrenCacheListener() &#123; @Override public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception &#123; if (event.getType().equals(PathChildrenCacheEvent.Type.CHILD_REMOVED)) &#123; String oldPath = event.getData().getPath(); log.info("success to release lock for path:&#123;&#125;", oldPath); if (oldPath.contains(path)) &#123; //释放计数器，让当前的请求获取锁 countDownLatch.countDown(); &#125; &#125; &#125; &#125;); &#125; /** * 初始化创建永久父节点 */ @Override public void afterPropertiesSet() &#123; curatorFramework = curatorFramework.usingNamespace("lock-namespace"); String path = "/" + ROOT_PATH_LOCK; try &#123; if (curatorFramework.checkExists().forPath(path) == null) &#123; curatorFramework .create() .creatingParentsIfNeeded() .withMode(CreateMode.PERSISTENT) .withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE) .forPath(path); &#125; addWatcher(ROOT_PATH_LOCK); log.info("root path 的 watcher 事件创建成功"); &#125; catch (Exception e) &#123; log.error("connect zookeeper fail，please check the log &gt;&gt; &#123;&#125;", e.getMessage(), e); &#125; &#125;&#125; 完整代码https://github.com/austin-brant/zookeeper-spring-boot Curator使用参考Curator包含了几个包： curator-framework：对zookeeper的底层api的一些封装 curator-client：提供一些客户端的操作，例如重试策略等 curator-recipes：封装了一些高级特性，如：Cache事件监听、选举、分布式锁、分布式计数器、分布式Barrier等 Maven依赖(使用curator的版本：2.12.0，对应Zookeeper的版本为：3.4.x，如果跨版本会有兼容性问题，很有可能导致节点操作失败)： Curator使用详解参考：Zookeeper客户端Curator使用详解]]></content>
      <categories>
        <category>Spring-Boot</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github Page + Hexo + Next 搭建个人博客]]></title>
    <url>%2F2019%2F07%2F11%2FGithub-Page-Hexo-Next-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 准备环境准备 node 和 git 环境， 安装NodeJs首先，安装 NodeJS，因为 Hexo 是基于 Node.js 驱动的一款博客框架，相比起前面提到过的 Jekyll 框架更快更简洁。 安装git然后，安装 git，一个分布式版本控制系统，用于项目的版本控制管理，作者是 Linux 之父。如果 Git 还不熟悉可以参考廖雪峰大神的 Git 教程。 在命令行中输入相应命令验证是否成功，如果成功会有相应的版本号。 123git versionnode -vnpm -v 安装 Hexo安装如果以上环境准备好了就可以使用 npm 开始安装 Hexo 了。也可查看 Hexo 的详细文档。在命令行输入执行以下命令： 1npm install -g hexo-cli 预览安装 Hexo 完成后，再执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 123hexo init myBlogcd myBlognpm install 新建完成后，指定文件夹的目录如下： 12345678.├── _config.yml # 网站的配置信息，您可以在此配置大部分的参数。 ├── package.json├── scaffolds # 模版文件夹├── source # 资源文件夹，除 _posts 文件，其他以下划线_开头的文件或者文件夹不会被编译打包到public文件夹| ├── _drafts # 草稿文件| └── _posts # 文章Markdowm文件 └── themes # 主题文件夹 好了，如果上面的命令都没报错的话，就恭喜了，运行 1hexo s 命令，其中 s 是 server 的缩写，在浏览器中输入 http://localhost:4000 回车就可以预览效果了。 配置GitHub Page首先如果你还没有 Github 账号的先 注册 一个。然后创建git hub同名仓库。 PS: Github 仅能使用一个同名仓库的代码托管一个静态站点 然后打开仓库创建一个 index.html 文件，并随意先写点内容，比如 Hello World. 这个时候打开 http://你的用户名.github.io 就可以看到你的站点啦，是不是很简单！index.html 内容只是暂时的预览效果，后面把 Hexo 的文件部署上去就可以在 http://你的用户名.github.io 看到你自己的博客啦！ 部署到 Github此时，本地和Github的工作做得差不了，是时候把它们两个连接起来了。你也可以查看官网的部署教程。先不着急，部署之前还需要修改配置和安装部署插件。第一：打开项目根目录下的 _config.yml 配置文件配置参数。拉到文件末尾，填上如下配置（也可同时部署到多个仓库，后面再说）： 第二：要安装一个部署插件 hexo-deployer-git。 1npm install hexo-deployer-git --save 最后执行以下命令就可以部署上传啦，以下 g 是 generate 缩写，d 是 deploy 缩写： 1hexo g -d 稍等一会，在浏览器访问网址： https://你的用户名.github.io 就会看到你的博客啦！！ Hexo写作头部规则相关设置文章中的头部会需要根据规则编写标题、更新时间，标签分类等类容。对读者是不可见的，语法如下： 1234567---title: Git添加账号date: 2017-06-08 19:49:26tags: [git]categories: gitcomments: true--- 以下是预先定义的参数，您可在模板中使用这些参数值并加以利用。 参数 描述 默认值 说明 layout 布局 title 标题 date 建立日期 文件建立日期 updated 更新日期 文件更新日期 comments 开启文章的评论功能 true tags 标签（不适用于分页） categories 分类（不适用于分页） permalink 覆盖文章网址 只有文章支持分类和标签.在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 Foo, Bar 不等于 Bar, Foo；而标签没有顺序和层次。 12345categories:- Diarytags:- PS3- Games 常用Hexo指令官方文档： https://hexo.io/zh-cn/docs/commands init1hexo init [folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new1hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 1hexo new &quot;post title with whitespace&quot; generate1$ hexo generate 生成静态文件。 123选项 描述-d, --deploy 文件生成后立即部署网站-w, --watch 监视文件变动 该命令可以简写为 1$ hexo g deploy1$ hexo deploy 部署网站。 12参数 描述-g, --generate 部署之前预先生成静态文件 该命令可以简写为： 1$ hexo d clean1$ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 server1$ hexo server 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 1234选项 描述-p, --port 重设端口-s, --static 只使用静态文件-l, --log 启动日记记录，使用覆盖记录格式 该命令可以简写： 1$ hexo s 多终端编辑如果我想要在公司写博客怎么办，或者说如果我换电脑了怎么办，因为在github中的我们github.io项目是只有编译后的文件的，没有源文件的，也就是说，如果我们的电脑坏了，打不开了，我们的博客就不能进行更新了，所以需要把源文件也上传到github（或者Coding）上，然后对我们的源文件进行版本管理，这样我们就可以在另一台电脑上pull我们的源码，然后编译完之后push上去。 配置提交git将博客编辑路径hexo配置及soure文件等提交到git hub仓库；为了筛选出配置文件、主题目录、博文等重要信息，作为需要GItHub管理的文件, public内文件是根据source文件夹内容自动生成，不需要备份，不然每次改动内容太多, 即使是私有仓库，除去在线服务商员工可以看到的风险外，还有云服务商被攻击造成泄漏等可能，所以不建议将配置文件传上去。.gitignore文件： 12345678.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/_config.yml 注意这里有个坑！！！如果你用的是第三方的主题theme，是使用git clone下来的话，要把主题文件夹下面把.git文件夹删除掉，不然主题无法push到远程仓库，导致你发布的博客是一片空白。 另一台电脑操作 首先需要搭建环境（Node，Git） 安装Hexo 1npm install -g hexo-cli 拉上一步提交的代码到本地进入文件路径执行 1hexo g 然后根据提示进行操作即可。 发布报错错误如下 12345678Connection to github.com closed by remote host.fatal: The remote end hung up unexpectedlyerror: failed to push some refs to &apos;git@github.com:xxxxx/xxxxx.github.io.git&apos;FATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: Spawn failed at ChildProcess.&lt;anonymous&gt; (/home/pi/blog/node_modules/_hexo-util@0.6.3@hexo-util/lib/spawn.js:52:19) at ChildProcess.emit (events.js:182:13) at Process.ChildProcess._handle.onexit (internal/child_process.js:240:12) 这个错误是因为本地的博客版本与远程的版本不一致，解决方法: 删除博客目录下的.deploy_git文件夹，然后克隆远程(也就是将要发布的地址)的仓库到博客目录里面，然后改名字为.deploy_git 另外一个不那么绕的办法是把远端仓库删除，删除本地的.deploy_git，再次发布，不过这样做会导致之前的提交记录丢失。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Spring-Boot]过滤器vs拦截器]]></title>
    <url>%2F2019%2F07%2F10%2FSpring-Boot-%E8%BF%87%E6%BB%A4%E5%99%A8vs%E6%8B%A6%E6%88%AA%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言在spring-boot中，经常会用到滤器和拦截器，但是什么场景适合用过滤器，什么场景适合用拦截器，而且有什么异同点？下面来详细分析一下。 过滤器过滤器Filter，是在Servlet规范中定义的，是Servlet容器支持的，该接口定义在javax.servlet包下，主要是在客户端请求(HttpServletRequest)进行预处理，以及对服务器响应(HttpServletResponse)进行后处理。接口代码如下: 1234567891011package javax.servlet;import java.io.IOException;public interface Filter &#123; void init(FilterConfig var1) throws ServletException; void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException; void destroy();&#125; 对上面三个接口方法进行分析: init(FilterConfig)初始化接口，在用户自定义的Filter初始化时被调用，它与Servlet的 init方法的作用是一样的。 doFilter(ServletRequest,ServletResponse,FilterChain)在每个用户的请求进来时这个方法都会被调用，并在Servlet的service方法之前调用(如果我们是开发Servlet项目)，而FilterChain就代表当前的整个请求链，通过调用 FilterChain.doFilter可以将请求继续传递下去，如果想拦截这个请求，可以不调用FilterChain.doFilter，那么这个请求就直接返回了，所以Filter是一种责任链设计模式，在spring security就大量使用了过滤器，有一条过滤器链。 destroy当Filter对象被销毁时，这个方法被调用，注意，当Web容器调用这个方法之后，容器会再调用一次doFilter方法。 自定义Filter过滤器在springboot自定义Filter类如下: 123456789101112131415161718192021@Componentpublic class MyFilter implements Filter &#123; private Logger logger = LoggerFactory.getLogger(MyFilter.class); @Override public void init(FilterConfig filterConfig) throws ServletException &#123; logger.info("filter init"); &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; logger.info("doFilter"); //对request,response进行预处理 //TODO 进行业务逻辑 filterChain.doFilter(servletRequest, servletResponse); &#125; @Override public void destroy() &#123; logger.info("filter destroy"); &#125;&#125; FilterRegistrationBean方式在springboot中提供了FilterRegistrationBean方式，此类提供setOrder方法，可以为多个filter设置排序值。代码如下: 1234567891011121314151617181920212223242526272829303132333435@Configurationpublic class FilterConfig &#123; /** * 配置一个Filter注册器 * * @return */ @Bean public FilterRegistrationBean filterRegistrationBean1() &#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(filter1()); registrationBean.setName("filter1"); //设置顺序 registrationBean.setOrder(10); return registrationBean; &#125; @Bean public FilterRegistrationBean filterRegistrationBean2() &#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(filter2()); registrationBean.setName("filter2"); //设置顺序 registrationBean.setOrder(3); return registrationBean; &#125; @Bean public Filter filter1() &#123; return new MyFilter(); &#125; @Bean public Filter filter2() &#123; return new MyFilter2(); &#125;&#125; 拦截器拦截器是Spring提出的概念，它的作用于过滤器类似，可以拦截用户请求并进行相应的处理，它可以进行更加精细的控制。在SpringMVC中，DispatcherServlet捕获每个请求，在到达对应的Controller之前，请求可以被拦截器处理，在拦截器中进行前置处理后，请求最终才到达Controller。 拦截器的接口是org.springframework.web.servlet.HandlerInterceptor接口，接口代码如下: 1234567891011public interface HandlerInterceptor &#123; default boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return true; &#125; default void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception &#123; &#125; default void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception &#123; &#125;&#125; 复制代码接口方法解读: preHandle方法对客户端发过来的请求进行前置处理，如果方法返回true,继续执行后续操作，如果返回false，执行中断请求处理，请求不会发送到Controller postHandler方法在请求进行处理后执行，也就是在Controller方法调用之后处理，当然前提是之前的 preHandle方法返回 true。具体来说，postHandler方法会在DispatcherServlet进行视图返回渲染前被调用，也就是说我们可以在这个方法中对 Controller 处理之后的ModelAndView对象进行操作 afterCompletion方法该方法在整个请求结束之后执行，当然前提依然是 preHandle方法的返回值为 true才行。该方法一般用于资源清理工作. 自定义拦截器123456789101112131415161718public class MyInterceptor implements HandlerInterceptor &#123; private Logger logger = LoggerFactory.getLogger(MyInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; logger.info("preHandle...."); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; logger.info("postHandle..."); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; logger.info("afterCompletion..."); &#125;&#125; 注册拦截器同时配置拦截器规则12345678910111213@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(handlerInterceptor()) //配置拦截规则 .addPathPatterns("/**"); &#125; @Bean public HandlerInterceptor handlerInterceptor() &#123; return new MyInterceptor(); &#125;&#125; 多个拦截器协同工作在springMVC中我们可以实现多个拦截器，并依次将他们注册进去，如下： 123456public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(handlerInterceptor()) .addPathPatterns("/**"); registry.addInterceptor(handlerInterceptor2()) .addPathPatterns("/**");&#125; 拦截器的顺序也跟他们注册时的顺序有关，至少 preHandle方法是这样，下图表示了两个拦截器协同工作时的执行顺序： 后台打印日志显示了执行顺序： 1234567io-9999-exec-2] c.p.filter.interceptor.MyInterceptor : preHandle....2018-09-13 12:13:31.292 INFO 9736 --- [nio-9999-exec-2] c.p.filter.interceptor.MyInterceptor2 : preHandle2....2018-09-13 12:13:31.388 INFO 9736 --- [nio-9999-exec-2] c.p.filter.controller.HelloController : username:pjmike,password:1234562018-09-13 12:13:31.418 INFO 9736 --- [nio-9999-exec-2] c.p.filter.interceptor.MyInterceptor2 : postHandle2...2018-09-13 12:13:31.418 INFO 9736 --- [nio-9999-exec-2] c.p.filter.interceptor.MyInterceptor : postHandle...2018-09-13 12:13:31.418 INFO 9736 --- [nio-9999-exec-2] c.p.filter.interceptor.MyInterceptor2 : afterCompletion2...2018-09-13 12:13:31.418 INFO 9736 --- [nio-9999-exec-2] c.p.filter.interceptor.MyInterceptor : afterCompletion... 拦截器与过滤器之间的区别从上面对拦截器与过滤器的描述来看，它俩是非常相似的，都能对客户端发来的请求进行处理，它们的区别如下： 作用域不同 过滤器依赖于servlet容器，只能在 servlet容器，web环境下使用 拦截器依赖于spring容器，可以在spring容器中调用，不管此时Spring处于什么环境 细粒度的不同 过滤器的控制比较粗，只能在请求进来时进行处理，对请求和响应进行包装 拦截器提供更精细的控制，可以在controller对请求处理之前或之后被调用，也可以在渲染视图呈现给用户之后调用 中断链执行的难易程度不同 拦截器可以 preHandle方法内返回 false 进行中断 过滤器就比较复杂，需要处理请求和响应对象来引发中断，需要额外的动作，比如将用户重定向到错误页面 小结简单总结一下，拦截器相比过滤器有更细粒度的控制，依赖于Spring容器，可以在请求之前或之后启动，过滤器主要依赖于servlet，过滤器能做的，拦截器基本上都能做。 [转载] springboot系列文章之过滤器 vs 拦截器]]></content>
      <tags>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx Https 配置]]></title>
    <url>%2F2019%2F07%2F10%2FNginx-Https-%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Https配置简介要保证Web浏览器到服务器的安全连接，HTTPS几乎是唯一选择。HTTPS其实就是HTTP over SSL，也就是让HTTP连接建立在SSL安全连接之上。 SSL使用证书来创建安全连接。有两种验证模式： 1 仅客户端验证服务器的证书，客户端自己不提供证书； 2 客户端和服务器都互相验证对方的证书。 显然第二种方式安全性更高，一般用网上银行会这么搞，但是，Dayu服务只需要采用第一种方式就可以。 SSL证书服务器自己的证书必须经过某“权威”证书的签名，而这个“权威”证书又可能经过更权威的证书签名，这么一级一级追溯上去，最顶层那个最权威的证书就称为根证书。根证书直接内置在浏览器中，这样，浏览器就可以利用自己自带的根证书去验证某个服务器的证书是否有效。 SSL证书级别分为三种类型，域名型SSL证书（DV SSL）、企业型SSL证书（OVSSL）、增强型SSL证书（EVSSL） 1. 域名型 SSL 证书（DV SSL - Domain Validation SSL）即证书颁布机构只对域名的所有者进行在线检查，通常是验证域名下某个指定文件的内容，或者验证与域名相关的某条 TXT 记录； 比如访问 [http|https]://www.mimvp.com/.../test.txt，文件内容： 2016082xxxxxmimvpcom2016 或添加一条 TXT 记录：www.mimvp.com –&gt; TXT –&gt; 20170xxxxxmimvpcom2066 2. 企业型 SSL 证书（OV SSL - Organization Validation SSL）是要购买者提交组织机构资料和单位授权信等在官方注册的凭证， 证书颁发机构在签发 SSL 证书前，不仅仅要检验域名所有权， 还必须对这些资料的真实合法性进行多方查验，只有通过验证的才能颁发 SSL 证书。 3. 增强型 SSL 证书（EV SSL - Extended Validation SSL）与其他 SSL 证书一样，都是基于 SSL/TLS 安全协议， 但是验证流程更加具体详细，验证步骤更多， 这样一来证书所绑定的网站就更加的可靠、可信。 它跟普通 SSL 证书的区别也是明显的，安全浏览器的地址栏变绿， 如果是不受信的 SSL 证书则拒绝显示，如果是钓鱼网站，地址栏则会变成红色，以警示用户。 证书获取在此就不详细介绍了 自签名证书生成下面简单介绍如何创建一个自签名的SSL证书。执行脚本create_cert.sh即可。 12345678910111213141516171819202122232425#!/bin/bash## 生成秘钥key## 会有两次要求输入密码,输入同一个即可,## 然后你就获得了一个server.key文件.openssl genrsa -des3 -out server.key 2048## 以后使用此文件(通过openssl提供的命令或API)可能经常回要求输入密码## 如果想去除输入密码的步骤可以使用以下命令:openssl rsa -in server.key -out server.key## 创建服务器证书的申请文件server.csr## 其中Country Name填CN,Common Name填主机名也可以不填,如果不填浏览器会认为不安全.## (例如你以后的url为https://abcd/xxxx....这里就可以填abcd),其他的都可以不填.openssl req -new -key server.key -out server.csr## 创建CA证书## 此时,你可以得到一个ca.crt的证书,这个证书用来给自己的证书签名.openssl req -new -x509 -key server.key -out ca.crt -days 3650## 创建自当前日期起有效期为期十年的服务器证书server.crtopenssl x509 -req -days 3650 -in server.csr -CA ca.crt -CAkey server.key -CAcreateserial -out server.crt 其中第三条指令在第二步第二条时会出来一个填写资料的界面（我已经填好参考，有些地方可以空着） 1234567Country Name (2 letter code) [AU]:CNState or Province Name (full name) [Some-State]:BEIJINGLocality Name (eg, city) []:haidianOrganization Name (eg, company) [Internet Widgits Pty Ltd]:BaiduOrganizational Unit Name (eg, section) []:Common Name (e.g. server FQDN or YOUR name) []:localhostEmail Address []: 这里有点要注意， Common Name (e.g. server FQDN or YOUR name) []: 这一项，是最后可以访问的域名，我这里为了方便测试，写成 localhost ，如果是为了给网站生成证书，需要写成 xxxx.com 。 脚本执行完成后，ls你的文件夹,可以看到一共生成了5个文件:ca.crt ca.srl server.crt server.csr server.key其中,server.crt和server.key就是你的nginx需要的证书文件. 配置nginx(1) 查看nginx是否安装了ssl模块 nginx -V 又红框中标记内容，则表示已经安装了ssl模块，否则需要手动安装或是更换nginx版本。 ###（2）配置nginx 将之前生成的密钥及证书文件server.crt和server.key拷贝到nginx配置文件nginx.conf同级目录，然后修改nginx.conf. 1234567891011121314151617181920212223242526272829303132333435363738394041424344# HTTPS serverserver &#123; listen 443 ssl; server_name localhost; # 域名 ssl_certificate server.crt; ssl_certificate_key server.key; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / &#123; root /home/bigdata/dayu/www/; index index.html; proxy_set_header Host $http_host; rewrite (.*) /index.html break; &#125; location /public/ &#123; root /home/bigdata/dayu/www; &#125; location /metamap/ &#123; proxy_pass http://127.0.0.1:8083/; proxy_redirect /metamap/ http://127.0.0.1:8083/; proxy_set_header Host $http_host; &#125; location /bflow/ &#123; proxy_pass http://127.0.0.1:8084/; proxy_redirect /workflow/ http://127.0.0.1:8084/; proxy_set_header Host $http_host; &#125; location /authenticate/ &#123; proxy_pass http://cp01-mxnet-test.epc.baidu.com:8010/; proxy_redirect /authenticate/ http://127.0.0.1:8082/; proxy_set_header Host $http_host; &#125; &#125;]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Https</tag>
      </tags>
  </entry>
</search>
